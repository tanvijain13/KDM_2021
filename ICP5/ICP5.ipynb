{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP5.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/tanvijain13/KDM_2021/blob/main/ICP5/ICP5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyrx50EW0M1l"
      },
      "source": [
        "# Installing the Library\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k8Pnb_Y42ItU"
      },
      "source": [
        "## Importing 5 text files and reading them"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFnMnz2-0R30"
      },
      "source": [
        "text1 = open(\"/content/text1.txt\",\"r+\")\n",
        "text2 = open(\"/content/text2.txt\",\"r+\")\n",
        "text3 = open(\"/content/text3.txt\",\"r+\")\n",
        "text4 = open(\"/content/text4.txt\",\"r+\")\n",
        "text5 = open(\"/content/text5.txt\",\"r+\")\n",
        "\n",
        "docA = text1.read()\n",
        "docB = text2.read()\n",
        "docC = text3.read()\n",
        "docD = text4.read()\n",
        "docE = text5.read()"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "id": "c-gBYLAa2YWM",
        "outputId": "08fac392-abe1-4cad-e1e8-b23269c25eb2"
      },
      "source": [
        "# Printing first document\n",
        "docA"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Data Science Central does exactly what its name suggests and acts as an online resource hub for just about everything related to data science and big data. The site covers a wide array of data science topics regarding analytics, technology, tools, data visualization, code, and job opportunities. Industry experts contribute discussion and insights about key topics. The site updates frequently, nearly two blog posts a day from contributing writers, and it also offers a community forum for discussion or questions.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X2BQK7ZH2fY0"
      },
      "source": [
        "## Splitting string into words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5GKwnf_X0oZJ"
      },
      "source": [
        "WordsA = docA.split(' ')\n",
        "WordsB = docB.split(' ')\n",
        "WordsC = docC.split(' ')\n",
        "WordsD = docD.split(' ')\n",
        "WordsE = docE.split(' ')"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZzwaGsbt002N",
        "outputId": "d147297f-b518-4ec8-a95f-77d74e472b95"
      },
      "source": [
        "# Printing the split words of the first document\n",
        "print(WordsA)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Data', 'Science', 'Central', 'does', 'exactly', 'what', 'its', 'name', 'suggests', 'and', 'acts', 'as', 'an', 'online', 'resource', 'hub', 'for', 'just', 'about', 'everything', 'related', 'to', 'data', 'science', 'and', 'big', 'data.', 'The', 'site', 'covers', 'a', 'wide', 'array', 'of', 'data', 'science', 'topics', 'regarding', 'analytics,', 'technology,', 'tools,', 'data', 'visualization,', 'code,', 'and', 'job', 'opportunities.', 'Industry', 'experts', 'contribute', 'discussion', 'and', 'insights', 'about', 'key', 'topics.', 'The', 'site', 'updates', 'frequently,', 'nearly', 'two', 'blog', 'posts', 'a', 'day', 'from', 'contributing', 'writers,', 'and', 'it', 'also', 'offers', 'a', 'community', 'forum', 'for', 'discussion', 'or', 'questions.']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbGppLw82ufi"
      },
      "source": [
        "## Removing all duplicate words from all 5 text documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sw4_1bGs2WYl",
        "outputId": "a4ef39c1-4db0-4e3d-8888-4446ecb4e9ff"
      },
      "source": [
        "uniqueWords = set(bagOfWordsA).union(set(bagOfWordsB)).union(set(bagOfWordsC)).union(set(bagOfWordsD)).union(set(bagOfWordsE))\n",
        "print(\"Total Number of Unique Words: \",len(uniqueWords))"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Number of Unique Words:  426\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVmP6X3_3W4Q"
      },
      "source": [
        "## Creating Dictionary of Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PZ9M0hD2tYS"
      },
      "source": [
        "numOfWordsA = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsA:\n",
        "    numOfWordsA[word] += 1\n",
        "numOfWordsB = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsB:\n",
        "    numOfWordsB[word] += 1\n",
        "numOfWordsC = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsC:\n",
        "    numOfWordsC[word] += 1\n",
        "numOfWordsD = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsD:\n",
        "    numOfWordsD[word] += 1\n",
        "numOfWordsE = dict.fromkeys(uniqueWords, 0)\n",
        "for word in bagOfWordsE:\n",
        "    numOfWordsE[word] += 1"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fluAJXWX31fI"
      },
      "source": [
        "\n",
        "### Term Frequency (TF)\n",
        "The number of times a word appears in a document divided by the total number of words in the document. Every document has its own term frequency.\n",
        "\n",
        "**Removing all stopwords**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEV0srV3MqBA",
        "outputId": "033c1c76-f6f3-42dd-c87b-4a932347b91f"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDHWABaq3cNy"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stopwords.words('english')\n",
        "def computeTF(wordDict, bagOfWords):\n",
        "    tfDict = {}\n",
        "    bagOfWordsCount = len(bagOfWords)\n",
        "    for word, count in wordDict.items():\n",
        "        tfDict[word] = count / float(bagOfWordsCount)\n",
        "    return tfDict"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LrsOzMpj3l6I"
      },
      "source": [
        "term_freqA = computeTF(numOfWordsA, bagOfWordsA)\n",
        "term_freqB = computeTF(numOfWordsB, bagOfWordsB)\n",
        "term_freqC = computeTF(numOfWordsC, bagOfWordsC)\n",
        "term_freqD = computeTF(numOfWordsD, bagOfWordsD)\n",
        "term_freqE = computeTF(numOfWordsE, bagOfWordsE)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fi6K--zM4G0g"
      },
      "source": [
        "### Printing the term frequency of all 5 documents"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i-iChfK-3n_U",
        "outputId": "35066bd3-c302-4b1d-be6e-4348c22b5fe8"
      },
      "source": [
        "print(term_freqA)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': 0.0375, 'understanding': 0.0, 'architecture': 0.0, '': 0.0, 'this': 0.0, 'required': 0.0, 'connect': 0.0, 'frequently,': 0.0125, 'management': 0.0, 'care': 0.0, 'maximize': 0.0, 'handle': 0.0, 'approach': 0.0, 'management,': 0.0, 'COVID-19': 0.0, 'state': 0.0, 'examples': 0.0, 'integrate': 0.0, 'IBM,': 0.0, 'learns': 0.0, 'concerns': 0.0, 'real': 0.0, 'quickly': 0.0, 'case': 0.0, 'between': 0.0, 'resources,': 0.0, 'made': 0.0, 'Data,': 0.0, 'exponential': 0.0, 'platform.': 0.0, 'confront': 0.0, 'Ladder': 0.0, 'only': 0.0, 'add': 0.0, 'as-a-Service': 0.0, 'guided': 0.0, 'well': 0.0, 'more': 0.0, 'has': 0.0, 'organization.': 0.0, 'suggests': 0.0125, 'engagements.': 0.0, 'algorithms': 0.0, '30': 0.0, 'tools,': 0.0125, 'transform': 0.0, 'unsupervised': 0.0, 'services': 0.0, 'redefine': 0.0, 'on': 0.0, 'Learning\\n\\nReinforcement': 0.0, 'It': 0.0, 'offer': 0.0, 'you': 0.0, 'Service.': 0.0, 'services,': 0.0, 'will': 0.0, 'Cloud.': 0.0, 'formalized': 0.0, 'trying': 0.0, 'problem.': 0.0, 'DataOps': 0.0, 'innovative': 0.0, 'Eliminate': 0.0, 'modernize': 0.0, 'continues': 0.0, 'technology,': 0.0125, 'Pak': 0.0, 'does': 0.0125, 'day': 0.0125, 'if': 0.0, 'supervised': 0.0, 'planned,': 0.0, 'enterprise': 0.0, 'other': 0.0, 'help': 0.0, 'these': 0.0, 'address': 0.0, 'community': 0.0125, 'learned': 0.0, 'effectively': 0.0, 'Central': 0.0125, 'use': 0.0, 'analytics,': 0.0125, 'normal.”': 0.0, 'digitally': 0.0, 'OpenScale,': 0.0, 'succeed': 0.0, 'leading': 0.0, 'environment.': 0.0, 'Studio,': 0.0, 'depth': 0.0, 'spanning': 0.0, 'storage': 0.0, 'sources,': 0.0, 'or': 0.0125, 'many,': 0.0, 'over': 0.0, 'latter': 0.0, 'challenges': 0.0, 'model': 0.0, 'focus': 0.0, 'exactly': 0.0125, 'ML,': 0.0, 'own': 0.0, 'understand': 0.0, 'be': 0.0, 'wide': 0.0125, 'AI,': 0.0, 'include': 0.0, 'of': 0.0125, 'aspirations': 0.0, 'initial': 0.0, 'value': 0.0, 'contributing': 0.0125, 'Cloud': 0.0, 'tighter': 0.0, 'want': 0.0, 'The': 0.025, 'Give': 0.0, 'including': 0.0, 'governance': 0.0, 'reinforcement': 0.0, 'results.': 0.0, 'hand,': 0.0, 'learn.': 0.0, 'framework,': 0.0, 'managed': 0.0, 'ingestion': 0.0, 'and': 0.0625, 'Data': 0.0125, 'methodology': 0.0, '2018,': 0.0, 'provides': 0.0, 'entry': 0.0, 'offers': 0.0125, 'developed': 0.0, 'Learning\\n\\nIn': 0.0, 'faster': 0.0, 'than': 0.0, 'labels': 0.0, 'is': 0.0, 'acts': 0.0125, 'beginning.': 0.0, 'knowledge': 0.0, 'today.': 0.0, 'learning': 0.0, 'both': 0.0, 'scale': 0.0, 'in': 0.0, 'full': 0.0, 'cloud.': 0.0, 'includes': 0.0, 'originally': 0.0, 'where': 0.0, 'barriers': 0.0, 'As': 0.0, 'infrastructure': 0.0, 'data.': 0.0125, 'that': 0.0, 'We': 0.0, 'users': 0.0, 'several': 0.0, 'each': 0.0, 'successful': 0.0, 'name': 0.0125, 'three': 0.0, 'let': 0.0, 'challenge': 0.0, 'impacting': 0.0, 'predict': 0.0, 'penalized': 0.0, 'big': 0.0125, 'insights': 0.0125, 'expenses.': 0.0, \"don't\": 0.0, 'entire': 0.0, 'Watson': 0.0, 'labels.': 0.0, 'platform': 0.0, 'attempt.\\n\\nThe': 0.0, 'it': 0.0125, 'Instead,': 0.0, 'key': 0.0125, 'we': 0.0, 'post,': 0.0, 'two': 0.0125, 'our': 0.0, 'webpage!\\n\\nSupervised': 0.0, 'AI': 0.0, 'related': 0.0125, 'modern': 0.0, 'code,': 0.0125, 'see': 0.0, 'when': 0.0, 'now': 0.0, 'provisioning,': 0.0, 'given': 0.0, 'science': 0.025, 'leaders': 0.0, 'that,': 0.0, 'techniques': 0.0, 'cloud': 0.0, 'integrated': 0.0, 'services.': 0.0, 'present.': 0.0, 'environment,': 0.0, 'pre-integrated': 0.0, 'mission.': 0.0, 'contribute': 0.0125, 'different': 0.0, 'under': 0.0, 'capabilities,': 0.0, 'multicloud': 0.0, 'patterns,': 0.0, 'implementation': 0.0, 'integration': 0.0, 'quickly,': 0.0, 'business.': 0.0, 'everything': 0.0125, 'with': 0.0, 'attempt.\\n\\nUnsupervised': 0.0, 'To': 0.0, 'through': 0.0, 'helping': 0.0, 'securely': 0.0, 'individual': 0.0, 'continuing': 0.0, 'end': 0.0, 'the': 0.0, 'find': 0.0, 'Machine': 0.0, 'information': 0.0, 'Service,': 0.0, 'array': 0.0125, 'at': 0.0, 'came': 0.0, 'Service': 0.0, 'lifecycle': 0.0, 'ultimate': 0.0, 'just': 0.0125, 'reward': 0.0, 'lessons': 0.0, 'right': 0.0, 'writers,': 0.0125, 'flexible': 0.0, 'what': 0.0125, 'questions.': 0.0125, 'tries': 0.0, 'unknown.\\n\\nReinforcement': 0.0, 'advanced': 0.0, 'access': 0.0, 'set': 0.0, 'areas': 0.0, 'Today,': 0.0, 'organization': 0.0, 'cycle.\\nBuilding': 0.0, 'flows': 0.0, 'visualization,': 0.0125, 'release': 0.0, 'talent': 0.0, 'solution': 0.0, 'its': 0.0125, 'across': 0.0, 'quiz': 0.0, '(features)': 0.0, 'initiatives.': 0.0, 'trained': 0.0, 'into': 0.0, 'industries': 0.0, 'discussion': 0.025, 'costly': 0.0, 'businesses': 0.0, 'nearly': 0.0125, 'A': 0.0, 'started': 0.0, 'tell': 0.0, 'try': 0.0, 'framework': 0.0, 'delivery:': 0.0, 'IBM': 0.0, 'These': 0.0, 'which': 0.0, 'needs': 0.0, 'for': 0.025, 'Knowledge': 0.0, 'site': 0.025, 'provide': 0.0, 'impart': 0.0, 'themselves': 0.0, 'available': 0.0, 'throughout': 0.0, 'regarding': 0.0125, 'Industry': 0.0125, 'benefits': 0.0, 'blog': 0.0125, 'test': 0.0, 'pain.\\nWe': 0.0, 'In': 0.0, 'learn': 0.0, 'analyze': 0.0, 'Get': 0.0, 'either': 0.0, 'assets.\\nThis': 0.0, 'turn': 0.0, 'beginning': 0.0, 'hub': 0.0125, 'as': 0.0125, 'deploying': 0.0, 'take': 0.0, 'how': 0.0, 'unified': 0.0, 'designed': 0.0, 'experts': 0.0125, 'can': 0.0, 'starter': 0.0, 'job': 0.0125, 'clients': 0.0, 'introduce': 0.0, 'For': 0.0, 'must-have': 0.0, 'choice.': 0.0, 'from': 0.0125, '“new': 0.0, 'This': 0.0, 'evolve,': 0.0, 'cohesively': 0.0, 'previous': 0.0, 'agent': 0.0, 'some': 0.0, 'infrastructure,': 0.0, 'looked': 0.0, 'even': 0.0, 'are': 0.0, 'provision': 0.0, 'an': 0.0125, 'analytics': 0.0, 'foundation': 0.0, 'topics.': 0.0125, 'we’ve': 0.0, 'Learning\\n\\nUnsupervised': 0.0, 'learning,': 0.0, 'answer.': 0.0, 'a': 0.0375, 'models,': 0.0, 'platform—and': 0.0, 'fully': 0.0, 'business': 0.0, 'life': 0.0, 'covers': 0.0125, 'capabilities.': 0.0, 'label(s)': 0.0, '30,000': 0.0, 'about': 0.025, 'integrations': 0.0, 'organize': 0.0, 'utilize': 0.0, 'then': 0.0, 'being': 0.0, 'online': 0.0125, 'while': 0.0, 'efficient': 0.0, 'was': 0.0, 'many': 0.0, 'considered': 0.0, 'board': 0.0, 'supplemental': 0.0, 'attributes': 0.0, 'also': 0.0125, 'infuse': 0.0, 'have': 0.0, 'grow,': 0.0, 'categories.': 0.0, 'fall': 0.0, 'give': 0.0, 'journey': 0.0, 'embed': 0.0, 'topics': 0.0125, 'end,': 0.0, 'updates': 0.0125, 'processes': 0.0, 'forum': 0.0125, 'self-service': 0.0, 'your': 0.0, 'minimizing': 0.0, 'bridges': 0.0, 'not': 0.0, 'less': 0.0, 'Science': 0.0125, 'dataset': 0.0, 'share': 0.0, 'Data.': 0.0, 'rewarded': 0.0, 'below': 0.0, '(labels)': 0.0, 'structures': 0.0, 'From': 0.0, 'answers': 0.0, 'Catalog': 0.0, 'business-ready': 0.0, 'prescriptive': 0.0, 'among': 0.0, 'found': 0.0, 'machine': 0.0, 'far': 0.0, 'underlying': 0.0, 'breadth': 0.0, 'opportunities.': 0.0125, 'collect,': 0.0, 'former': 0.0, 'interacting': 0.0, 'IT': 0.0, 'Learning,': 0.0, 'both.': 0.0, 'At': 0.0, 'so': 0.0, 'get': 0.0, 'attempts': 0.0, 'unique': 0.0, 'drag-and-drop': 0.0, 'hidden': 0.0, 'resource': 0.0125, 'posts': 0.0125, 'to': 0.0125, 'their': 0.0, 'forced': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ORfKejEu3vcE",
        "outputId": "21ebecc4-040a-442f-caa6-2311e57877c5"
      },
      "source": [
        "print(term_freqB)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': 0.0, 'understanding': 0.005780346820809248, 'architecture': 0.0, '': 0.0, 'this': 0.005780346820809248, 'required': 0.0, 'connect': 0.0, 'frequently,': 0.0, 'management': 0.0, 'care': 0.0, 'maximize': 0.005780346820809248, 'handle': 0.0, 'approach': 0.0, 'management,': 0.0, 'COVID-19': 0.0, 'state': 0.0, 'examples': 0.005780346820809248, 'integrate': 0.0, 'IBM,': 0.0, 'learns': 0.005780346820809248, 'concerns': 0.0, 'real': 0.0, 'quickly': 0.0, 'case': 0.0, 'between': 0.005780346820809248, 'resources,': 0.0, 'made': 0.005780346820809248, 'Data,': 0.0, 'exponential': 0.0, 'platform.': 0.0, 'confront': 0.0, 'Ladder': 0.0, 'only': 0.0, 'add': 0.0, 'as-a-Service': 0.0, 'guided': 0.0, 'well': 0.0, 'more': 0.0, 'has': 0.0, 'organization.': 0.0, 'suggests': 0.0, 'engagements.': 0.0, 'algorithms': 0.005780346820809248, '30': 0.0, 'tools,': 0.0, 'transform': 0.0, 'unsupervised': 0.005780346820809248, 'services': 0.0, 'redefine': 0.0, 'on': 0.005780346820809248, 'Learning\\n\\nReinforcement': 0.005780346820809248, 'It': 0.005780346820809248, 'offer': 0.0, 'you': 0.011560693641618497, 'Service.': 0.0, 'services,': 0.0, 'will': 0.005780346820809248, 'Cloud.': 0.0, 'formalized': 0.0, 'trying': 0.0, 'problem.': 0.0, 'DataOps': 0.0, 'innovative': 0.0, 'Eliminate': 0.0, 'modernize': 0.0, 'continues': 0.0, 'technology,': 0.0, 'Pak': 0.0, 'does': 0.005780346820809248, 'day': 0.0, 'if': 0.0, 'supervised': 0.023121387283236993, 'planned,': 0.0, 'enterprise': 0.0, 'other': 0.011560693641618497, 'help': 0.005780346820809248, 'these': 0.005780346820809248, 'address': 0.0, 'community': 0.0, 'learned': 0.0, 'effectively': 0.0, 'Central': 0.0, 'use': 0.0, 'analytics,': 0.0, 'normal.”': 0.0, 'digitally': 0.0, 'OpenScale,': 0.0, 'succeed': 0.0, 'leading': 0.0, 'environment.': 0.005780346820809248, 'Studio,': 0.0, 'depth': 0.0, 'spanning': 0.0, 'storage': 0.0, 'sources,': 0.0, 'or': 0.011560693641618497, 'many,': 0.0, 'over': 0.0, 'latter': 0.0, 'challenges': 0.0, 'model': 0.011560693641618497, 'focus': 0.0, 'exactly': 0.0, 'ML,': 0.011560693641618497, 'own': 0.005780346820809248, 'understand': 0.0, 'be': 0.0, 'wide': 0.0, 'AI,': 0.0, 'include': 0.005780346820809248, 'of': 0.011560693641618497, 'aspirations': 0.0, 'initial': 0.0, 'value': 0.0, 'contributing': 0.0, 'Cloud': 0.0, 'tighter': 0.0, 'want': 0.0, 'The': 0.0, 'Give': 0.005780346820809248, 'including': 0.0, 'governance': 0.0, 'reinforcement': 0.005780346820809248, 'results.': 0.0, 'hand,': 0.005780346820809248, 'learn.': 0.005780346820809248, 'framework,': 0.0, 'managed': 0.0, 'ingestion': 0.0, 'and': 0.017341040462427744, 'Data': 0.0, 'methodology': 0.0, '2018,': 0.0, 'provides': 0.0, 'entry': 0.0, 'offers': 0.0, 'developed': 0.0, 'Learning\\n\\nIn': 0.005780346820809248, 'faster': 0.0, 'than': 0.0, 'labels': 0.005780346820809248, 'is': 0.017341040462427744, 'acts': 0.0, 'beginning.': 0.0, 'knowledge': 0.005780346820809248, 'today.': 0.0, 'learning': 0.028901734104046242, 'both': 0.0, 'scale': 0.0, 'in': 0.005780346820809248, 'full': 0.0, 'cloud.': 0.0, 'includes': 0.0, 'originally': 0.0, 'where': 0.005780346820809248, 'barriers': 0.0, 'As': 0.0, 'infrastructure': 0.0, 'data.': 0.0, 'that': 0.005780346820809248, 'We': 0.0, 'users': 0.0, 'several': 0.0, 'each': 0.005780346820809248, 'successful': 0.0, 'name': 0.0, 'three': 0.005780346820809248, 'let': 0.0, 'challenge': 0.0, 'impacting': 0.0, 'predict': 0.005780346820809248, 'penalized': 0.005780346820809248, 'big': 0.0, 'insights': 0.0, 'expenses.': 0.0, \"don't\": 0.005780346820809248, 'entire': 0.0, 'Watson': 0.0, 'labels.': 0.005780346820809248, 'platform': 0.0, 'attempt.\\n\\nThe': 0.005780346820809248, 'it': 0.023121387283236993, 'Instead,': 0.005780346820809248, 'key': 0.0, 'we': 0.017341040462427744, 'post,': 0.005780346820809248, 'two': 0.0, 'our': 0.0, 'webpage!\\n\\nSupervised': 0.005780346820809248, 'AI': 0.0, 'related': 0.0, 'modern': 0.0, 'code,': 0.0, 'see': 0.0, 'when': 0.005780346820809248, 'now': 0.0, 'provisioning,': 0.0, 'given': 0.005780346820809248, 'science': 0.0, 'leaders': 0.0, 'that,': 0.005780346820809248, 'techniques': 0.005780346820809248, 'cloud': 0.0, 'integrated': 0.0, 'services.': 0.0, 'present.': 0.0, 'environment,': 0.0, 'pre-integrated': 0.0, 'mission.': 0.0, 'contribute': 0.0, 'different': 0.005780346820809248, 'under': 0.005780346820809248, 'capabilities,': 0.0, 'multicloud': 0.0, 'patterns,': 0.0, 'implementation': 0.0, 'integration': 0.0, 'quickly,': 0.0, 'business.': 0.0, 'everything': 0.0, 'with': 0.023121387283236993, 'attempt.\\n\\nUnsupervised': 0.005780346820809248, 'To': 0.0, 'through': 0.0, 'helping': 0.0, 'securely': 0.0, 'individual': 0.0, 'continuing': 0.0, 'end': 0.0, 'the': 0.06358381502890173, 'find': 0.005780346820809248, 'Machine': 0.011560693641618497, 'information': 0.0, 'Service,': 0.0, 'array': 0.0, 'at': 0.0, 'came': 0.0, 'Service': 0.0, 'lifecycle': 0.0, 'ultimate': 0.0, 'just': 0.0, 'reward': 0.005780346820809248, 'lessons': 0.0, 'right': 0.0, 'writers,': 0.0, 'flexible': 0.0, 'what': 0.005780346820809248, 'questions.': 0.0, 'tries': 0.005780346820809248, 'unknown.\\n\\nReinforcement': 0.005780346820809248, 'advanced': 0.0, 'access': 0.0, 'set': 0.0, 'areas': 0.005780346820809248, 'Today,': 0.0, 'organization': 0.0, 'cycle.\\nBuilding': 0.0, 'flows': 0.0, 'visualization,': 0.0, 'release': 0.0, 'talent': 0.0, 'solution': 0.0, 'its': 0.0, 'across': 0.0, 'quiz': 0.011560693641618497, '(features)': 0.005780346820809248, 'initiatives.': 0.0, 'trained': 0.005780346820809248, 'into': 0.005780346820809248, 'industries': 0.0, 'discussion': 0.0, 'costly': 0.0, 'businesses': 0.0, 'nearly': 0.0, 'A': 0.0, 'started': 0.0, 'tell': 0.005780346820809248, 'try': 0.005780346820809248, 'framework': 0.0, 'delivery:': 0.0, 'IBM': 0.0, 'These': 0.0, 'which': 0.005780346820809248, 'needs': 0.005780346820809248, 'for': 0.017341040462427744, 'Knowledge': 0.0, 'site': 0.0, 'provide': 0.0, 'impart': 0.0, 'themselves': 0.0, 'available': 0.0, 'throughout': 0.0, 'regarding': 0.0, 'Industry': 0.0, 'benefits': 0.0, 'blog': 0.0, 'test': 0.005780346820809248, 'pain.\\nWe': 0.0, 'In': 0.005780346820809248, 'learn': 0.005780346820809248, 'analyze': 0.0, 'Get': 0.0, 'either': 0.005780346820809248, 'assets.\\nThis': 0.0, 'turn': 0.0, 'beginning': 0.0, 'hub': 0.0, 'as': 0.0, 'deploying': 0.0, 'take': 0.0, 'how': 0.005780346820809248, 'unified': 0.0, 'designed': 0.0, 'experts': 0.0, 'can': 0.005780346820809248, 'starter': 0.0, 'job': 0.0, 'clients': 0.0, 'introduce': 0.005780346820809248, 'For': 0.0, 'must-have': 0.0, 'choice.': 0.0, 'from': 0.011560693641618497, '“new': 0.0, 'This': 0.005780346820809248, 'evolve,': 0.0, 'cohesively': 0.0, 'previous': 0.005780346820809248, 'agent': 0.005780346820809248, 'some': 0.0, 'infrastructure,': 0.0, 'looked': 0.0, 'even': 0.005780346820809248, 'are': 0.005780346820809248, 'provision': 0.0, 'an': 0.005780346820809248, 'analytics': 0.0, 'foundation': 0.0, 'topics.': 0.0, 'we’ve': 0.0, 'Learning\\n\\nUnsupervised': 0.005780346820809248, 'learning,': 0.011560693641618497, 'answer.': 0.005780346820809248, 'a': 0.017341040462427744, 'models,': 0.005780346820809248, 'platform—and': 0.0, 'fully': 0.0, 'business': 0.0, 'life': 0.0, 'covers': 0.0, 'capabilities.': 0.0, 'label(s)': 0.005780346820809248, '30,000': 0.0, 'about': 0.0, 'integrations': 0.0, 'organize': 0.0, 'utilize': 0.0, 'then': 0.005780346820809248, 'being': 0.0, 'online': 0.0, 'while': 0.005780346820809248, 'efficient': 0.0, 'was': 0.005780346820809248, 'many': 0.0, 'considered': 0.0, 'board': 0.0, 'supplemental': 0.0, 'attributes': 0.005780346820809248, 'also': 0.0, 'infuse': 0.0, 'have': 0.0, 'grow,': 0.0, 'categories.': 0.005780346820809248, 'fall': 0.005780346820809248, 'give': 0.005780346820809248, 'journey': 0.0, 'embed': 0.005780346820809248, 'topics': 0.0, 'end,': 0.0, 'updates': 0.0, 'processes': 0.0, 'forum': 0.0, 'self-service': 0.0, 'your': 0.011560693641618497, 'minimizing': 0.0, 'bridges': 0.0, 'not': 0.011560693641618497, 'less': 0.0, 'Science': 0.0, 'dataset': 0.011560693641618497, 'share': 0.005780346820809248, 'Data.': 0.0, 'rewarded': 0.005780346820809248, 'below': 0.005780346820809248, '(labels)': 0.005780346820809248, 'structures': 0.005780346820809248, 'From': 0.0, 'answers': 0.005780346820809248, 'Catalog': 0.0, 'business-ready': 0.0, 'prescriptive': 0.0, 'among': 0.0, 'found': 0.0, 'machine': 0.023121387283236993, 'far': 0.0, 'underlying': 0.0, 'breadth': 0.0, 'opportunities.': 0.0, 'collect,': 0.0, 'former': 0.0, 'interacting': 0.005780346820809248, 'IT': 0.0, 'Learning,': 0.0, 'both.': 0.0, 'At': 0.0, 'so': 0.005780346820809248, 'get': 0.0, 'attempts': 0.005780346820809248, 'unique': 0.0, 'drag-and-drop': 0.005780346820809248, 'hidden': 0.005780346820809248, 'resource': 0.0, 'posts': 0.0, 'to': 0.028901734104046242, 'their': 0.0, 'forced': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CEJiS8W4MKU",
        "outputId": "e62ca493-1bff-454e-90a1-6e3adba42410"
      },
      "source": [
        "print(term_freqC)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': 0.012345679012345678, 'understanding': 0.0, 'architecture': 0.00411522633744856, '': 0.0, 'this': 0.012345679012345678, 'required': 0.00411522633744856, 'connect': 0.0, 'frequently,': 0.0, 'management': 0.0, 'care': 0.0, 'maximize': 0.0, 'handle': 0.0, 'approach': 0.00411522633744856, 'management,': 0.0, 'COVID-19': 0.00411522633744856, 'state': 0.0, 'examples': 0.0, 'integrate': 0.0, 'IBM,': 0.00411522633744856, 'learns': 0.0, 'concerns': 0.00411522633744856, 'real': 0.00411522633744856, 'quickly': 0.0, 'case': 0.0, 'between': 0.0, 'resources,': 0.00411522633744856, 'made': 0.0, 'Data,': 0.00411522633744856, 'exponential': 0.00411522633744856, 'platform.': 0.00411522633744856, 'confront': 0.00411522633744856, 'Ladder': 0.00411522633744856, 'only': 0.0, 'add': 0.0, 'as-a-Service': 0.00411522633744856, 'guided': 0.0, 'well': 0.00411522633744856, 'more': 0.0, 'has': 0.0, 'organization.': 0.00411522633744856, 'suggests': 0.0, 'engagements.': 0.00411522633744856, 'algorithms': 0.0, '30': 0.0, 'tools,': 0.0, 'transform': 0.00411522633744856, 'unsupervised': 0.0, 'services': 0.00411522633744856, 'redefine': 0.00411522633744856, 'on': 0.00823045267489712, 'Learning\\n\\nReinforcement': 0.0, 'It': 0.0, 'offer': 0.00411522633744856, 'you': 0.00411522633744856, 'Service.': 0.00411522633744856, 'services,': 0.0, 'will': 0.0, 'Cloud.': 0.0, 'formalized': 0.00411522633744856, 'trying': 0.00411522633744856, 'problem.': 0.0, 'DataOps': 0.0, 'innovative': 0.00411522633744856, 'Eliminate': 0.0, 'modernize': 0.00411522633744856, 'continues': 0.0, 'technology,': 0.0, 'Pak': 0.012345679012345678, 'does': 0.0, 'day': 0.0, 'if': 0.0, 'supervised': 0.0, 'planned,': 0.00411522633744856, 'enterprise': 0.0, 'other': 0.00411522633744856, 'help': 0.0, 'these': 0.0, 'address': 0.00411522633744856, 'community': 0.0, 'learned': 0.00411522633744856, 'effectively': 0.0, 'Central': 0.0, 'use': 0.0, 'analytics,': 0.0, 'normal.”': 0.00411522633744856, 'digitally': 0.00411522633744856, 'OpenScale,': 0.0, 'succeed': 0.0, 'leading': 0.00411522633744856, 'environment.': 0.0, 'Studio,': 0.0, 'depth': 0.0, 'spanning': 0.00411522633744856, 'storage': 0.0, 'sources,': 0.0, 'or': 0.0, 'many,': 0.00411522633744856, 'over': 0.00411522633744856, 'latter': 0.0, 'challenges': 0.00411522633744856, 'model': 0.0, 'focus': 0.0, 'exactly': 0.0, 'ML,': 0.0, 'own': 0.0, 'understand': 0.00411522633744856, 'be': 0.00411522633744856, 'wide': 0.0, 'AI,': 0.00411522633744856, 'include': 0.0, 'of': 0.0205761316872428, 'aspirations': 0.00411522633744856, 'initial': 0.0, 'value': 0.00823045267489712, 'contributing': 0.0, 'Cloud': 0.012345679012345678, 'tighter': 0.0, 'want': 0.0, 'The': 0.00411522633744856, 'Give': 0.0, 'including': 0.0, 'governance': 0.0, 'reinforcement': 0.0, 'results.': 0.00411522633744856, 'hand,': 0.0, 'learn.': 0.0, 'framework,': 0.00411522633744856, 'managed': 0.0, 'ingestion': 0.0, 'and': 0.04526748971193416, 'Data': 0.00823045267489712, 'methodology': 0.00411522633744856, '2018,': 0.00411522633744856, 'provides': 0.00411522633744856, 'entry': 0.00411522633744856, 'offers': 0.0, 'developed': 0.00411522633744856, 'Learning\\n\\nIn': 0.0, 'faster': 0.00411522633744856, 'than': 0.00411522633744856, 'labels': 0.0, 'is': 0.012345679012345678, 'acts': 0.0, 'beginning.': 0.0, 'knowledge': 0.0, 'today.': 0.0, 'learning': 0.0, 'both': 0.00823045267489712, 'scale': 0.0, 'in': 0.0, 'full': 0.0, 'cloud.': 0.0, 'includes': 0.0, 'originally': 0.00411522633744856, 'where': 0.0, 'barriers': 0.00411522633744856, 'As': 0.0, 'infrastructure': 0.0, 'data.': 0.0, 'that': 0.00823045267489712, 'We': 0.00411522633744856, 'users': 0.0, 'several': 0.0, 'each': 0.0, 'successful': 0.00411522633744856, 'name': 0.0, 'three': 0.0, 'let': 0.0, 'challenge': 0.00411522633744856, 'impacting': 0.00411522633744856, 'predict': 0.0, 'penalized': 0.0, 'big': 0.0, 'insights': 0.0, 'expenses.': 0.00411522633744856, \"don't\": 0.0, 'entire': 0.00411522633744856, 'Watson': 0.0, 'labels.': 0.0, 'platform': 0.012345679012345678, 'attempt.\\n\\nThe': 0.0, 'it': 0.0, 'Instead,': 0.0, 'key': 0.00411522633744856, 'we': 0.012345679012345678, 'post,': 0.0, 'two': 0.0, 'our': 0.012345679012345678, 'webpage!\\n\\nSupervised': 0.0, 'AI': 0.0411522633744856, 'related': 0.0, 'modern': 0.0, 'code,': 0.0, 'see': 0.0, 'when': 0.00823045267489712, 'now': 0.00823045267489712, 'provisioning,': 0.0, 'given': 0.0, 'science': 0.0, 'leaders': 0.00411522633744856, 'that,': 0.0, 'techniques': 0.0, 'cloud': 0.00411522633744856, 'integrated': 0.00411522633744856, 'services.': 0.0, 'present.': 0.00411522633744856, 'environment,': 0.00411522633744856, 'pre-integrated': 0.0, 'mission.': 0.0, 'contribute': 0.0, 'different': 0.0, 'under': 0.0, 'capabilities,': 0.0, 'multicloud': 0.0, 'patterns,': 0.0, 'implementation': 0.00411522633744856, 'integration': 0.00411522633744856, 'quickly,': 0.0, 'business.': 0.0, 'everything': 0.0, 'with': 0.00411522633744856, 'attempt.\\n\\nUnsupervised': 0.0, 'To': 0.0, 'through': 0.00411522633744856, 'helping': 0.00411522633744856, 'securely': 0.0, 'individual': 0.0, 'continuing': 0.00411522633744856, 'end': 0.0, 'the': 0.04938271604938271, 'find': 0.0, 'Machine': 0.0, 'information': 0.00411522633744856, 'Service,': 0.0, 'array': 0.0, 'at': 0.00411522633744856, 'came': 0.00411522633744856, 'Service': 0.0, 'lifecycle': 0.0, 'ultimate': 0.0, 'just': 0.0, 'reward': 0.0, 'lessons': 0.00411522633744856, 'right': 0.0, 'writers,': 0.0, 'flexible': 0.00411522633744856, 'what': 0.0, 'questions.': 0.0, 'tries': 0.0, 'unknown.\\n\\nReinforcement': 0.0, 'advanced': 0.00411522633744856, 'access': 0.0, 'set': 0.0, 'areas': 0.0, 'Today,': 0.0, 'organization': 0.00411522633744856, 'cycle.\\nBuilding': 0.00411522633744856, 'flows': 0.0, 'visualization,': 0.0, 'release': 0.0, 'talent': 0.00411522633744856, 'solution': 0.00411522633744856, 'its': 0.00411522633744856, 'across': 0.00411522633744856, 'quiz': 0.0, '(features)': 0.0, 'initiatives.': 0.0, 'trained': 0.0, 'into': 0.00411522633744856, 'industries': 0.00411522633744856, 'discussion': 0.0, 'costly': 0.00411522633744856, 'businesses': 0.0, 'nearly': 0.0, 'A': 0.00411522633744856, 'started': 0.0, 'tell': 0.0, 'try': 0.0, 'framework': 0.00411522633744856, 'delivery:': 0.00411522633744856, 'IBM': 0.012345679012345678, 'These': 0.0, 'which': 0.0, 'needs': 0.0, 'for': 0.01646090534979424, 'Knowledge': 0.0, 'site': 0.0, 'provide': 0.00411522633744856, 'impart': 0.00411522633744856, 'themselves': 0.00411522633744856, 'available': 0.0, 'throughout': 0.00411522633744856, 'regarding': 0.0, 'Industry': 0.0, 'benefits': 0.00823045267489712, 'blog': 0.0, 'test': 0.0, 'pain.\\nWe': 0.0, 'In': 0.00823045267489712, 'learn': 0.0, 'analyze': 0.00411522633744856, 'Get': 0.0, 'either': 0.0, 'assets.\\nThis': 0.0, 'turn': 0.00411522633744856, 'beginning': 0.0, 'hub': 0.0, 'as': 0.012345679012345678, 'deploying': 0.00411522633744856, 'take': 0.0, 'how': 0.00411522633744856, 'unified': 0.00411522633744856, 'designed': 0.00411522633744856, 'experts': 0.0, 'can': 0.012345679012345678, 'starter': 0.0, 'job': 0.0, 'clients': 0.00411522633744856, 'introduce': 0.0, 'For': 0.00411522633744856, 'must-have': 0.0, 'choice.': 0.00411522633744856, 'from': 0.0, '“new': 0.00411522633744856, 'This': 0.0, 'evolve,': 0.0, 'cohesively': 0.0, 'previous': 0.0, 'agent': 0.0, 'some': 0.00411522633744856, 'infrastructure,': 0.00411522633744856, 'looked': 0.00411522633744856, 'even': 0.0, 'are': 0.00411522633744856, 'provision': 0.0, 'an': 0.00823045267489712, 'analytics': 0.00411522633744856, 'foundation': 0.00411522633744856, 'topics.': 0.0, 'we’ve': 0.00411522633744856, 'Learning\\n\\nUnsupervised': 0.0, 'learning,': 0.0, 'answer.': 0.0, 'a': 0.00823045267489712, 'models,': 0.0, 'platform—and': 0.0, 'fully': 0.0, 'business': 0.00823045267489712, 'life': 0.00411522633744856, 'covers': 0.0, 'capabilities.': 0.00411522633744856, 'label(s)': 0.0, '30,000': 0.00411522633744856, 'about': 0.0, 'integrations': 0.0, 'organize': 0.00411522633744856, 'utilize': 0.0, 'then': 0.0, 'being': 0.0, 'online': 0.0, 'while': 0.00411522633744856, 'efficient': 0.0, 'was': 0.0, 'many': 0.00411522633744856, 'considered': 0.0, 'board': 0.00411522633744856, 'supplemental': 0.0, 'attributes': 0.0, 'also': 0.00411522633744856, 'infuse': 0.00411522633744856, 'have': 0.00411522633744856, 'grow,': 0.0, 'categories.': 0.0, 'fall': 0.0, 'give': 0.0, 'journey': 0.0, 'embed': 0.0, 'topics': 0.0, 'end,': 0.0, 'updates': 0.0, 'processes': 0.0, 'forum': 0.0, 'self-service': 0.0, 'your': 0.012345679012345678, 'minimizing': 0.00411522633744856, 'bridges': 0.00411522633744856, 'not': 0.0, 'less': 0.0, 'Science': 0.0, 'dataset': 0.0, 'share': 0.0, 'Data.': 0.0, 'rewarded': 0.0, 'below': 0.0, '(labels)': 0.0, 'structures': 0.0, 'From': 0.00411522633744856, 'answers': 0.0, 'Catalog': 0.0, 'business-ready': 0.0, 'prescriptive': 0.00411522633744856, 'among': 0.0, 'found': 0.00411522633744856, 'machine': 0.0, 'far': 0.00411522633744856, 'underlying': 0.0, 'breadth': 0.0, 'opportunities.': 0.0, 'collect,': 0.00411522633744856, 'former': 0.0, 'interacting': 0.0, 'IT': 0.00411522633744856, 'Learning,': 0.0, 'both.': 0.0, 'At': 0.00411522633744856, 'so': 0.0, 'get': 0.0, 'attempts': 0.0, 'unique': 0.00411522633744856, 'drag-and-drop': 0.0, 'hidden': 0.0, 'resource': 0.0, 'posts': 0.0, 'to': 0.037037037037037035, 'their': 0.0, 'forced': 0.00411522633744856}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GxqUM3b24NOJ",
        "outputId": "e720ab30-3270-4571-87ec-f38a4c77cba1"
      },
      "source": [
        "print(term_freqD)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': 0.02142857142857143, 'understanding': 0.0, 'architecture': 0.0, '': 0.007142857142857143, 'this': 0.007142857142857143, 'required': 0.007142857142857143, 'connect': 0.007142857142857143, 'frequently,': 0.0, 'management': 0.014285714285714285, 'care': 0.007142857142857143, 'maximize': 0.0, 'handle': 0.007142857142857143, 'approach': 0.0, 'management,': 0.0, 'COVID-19': 0.0, 'state': 0.0, 'examples': 0.0, 'integrate': 0.0, 'IBM,': 0.0, 'learns': 0.0, 'concerns': 0.0, 'real': 0.0, 'quickly': 0.014285714285714285, 'case': 0.007142857142857143, 'between': 0.0, 'resources,': 0.0, 'made': 0.0, 'Data,': 0.0, 'exponential': 0.0, 'platform.': 0.0, 'confront': 0.0, 'Ladder': 0.0, 'only': 0.007142857142857143, 'add': 0.007142857142857143, 'as-a-Service': 0.0, 'guided': 0.007142857142857143, 'well': 0.0, 'more': 0.007142857142857143, 'has': 0.0, 'organization.': 0.0, 'suggests': 0.0, 'engagements.': 0.0, 'algorithms': 0.0, '30': 0.007142857142857143, 'tools,': 0.007142857142857143, 'transform': 0.0, 'unsupervised': 0.0, 'services': 0.014285714285714285, 'redefine': 0.0, 'on': 0.02142857142857143, 'Learning\\n\\nReinforcement': 0.0, 'It': 0.0, 'offer': 0.0, 'you': 0.014285714285714285, 'Service.': 0.0, 'services,': 0.014285714285714285, 'will': 0.007142857142857143, 'Cloud.': 0.007142857142857143, 'formalized': 0.0, 'trying': 0.0, 'problem.': 0.0, 'DataOps': 0.0, 'innovative': 0.0, 'Eliminate': 0.007142857142857143, 'modernize': 0.0, 'continues': 0.007142857142857143, 'technology,': 0.0, 'Pak': 0.02142857142857143, 'does': 0.0, 'day': 0.0, 'if': 0.0, 'supervised': 0.0, 'planned,': 0.0, 'enterprise': 0.007142857142857143, 'other': 0.0, 'help': 0.0, 'these': 0.0, 'address': 0.0, 'community': 0.0, 'learned': 0.0, 'effectively': 0.0, 'Central': 0.0, 'use': 0.007142857142857143, 'analytics,': 0.0, 'normal.”': 0.0, 'digitally': 0.0, 'OpenScale,': 0.0, 'succeed': 0.0, 'leading': 0.0, 'environment.': 0.0, 'Studio,': 0.0, 'depth': 0.0, 'spanning': 0.0, 'storage': 0.0, 'sources,': 0.007142857142857143, 'or': 0.0, 'many,': 0.0, 'over': 0.0, 'latter': 0.0, 'challenges': 0.007142857142857143, 'model': 0.0, 'focus': 0.007142857142857143, 'exactly': 0.0, 'ML,': 0.0, 'own': 0.0, 'understand': 0.0, 'be': 0.0, 'wide': 0.0, 'AI,': 0.0, 'include': 0.0, 'of': 0.02142857142857143, 'aspirations': 0.0, 'initial': 0.0, 'value': 0.0, 'contributing': 0.0, 'Cloud': 0.02142857142857143, 'tighter': 0.007142857142857143, 'want': 0.0, 'The': 0.0, 'Give': 0.0, 'including': 0.007142857142857143, 'governance': 0.007142857142857143, 'reinforcement': 0.0, 'results.': 0.0, 'hand,': 0.0, 'learn.': 0.0, 'framework,': 0.0, 'managed': 0.007142857142857143, 'ingestion': 0.0, 'and': 0.05714285714285714, 'Data': 0.02142857142857143, 'methodology': 0.0, '2018,': 0.0, 'provides': 0.007142857142857143, 'entry': 0.0, 'offers': 0.0, 'developed': 0.0, 'Learning\\n\\nIn': 0.0, 'faster': 0.0, 'than': 0.0, 'labels': 0.0, 'is': 0.007142857142857143, 'acts': 0.0, 'beginning.': 0.007142857142857143, 'knowledge': 0.0, 'today.': 0.007142857142857143, 'learning': 0.0, 'both': 0.0, 'scale': 0.007142857142857143, 'in': 0.0, 'full': 0.0, 'cloud.': 0.007142857142857143, 'includes': 0.0, 'originally': 0.0, 'where': 0.0, 'barriers': 0.0, 'As': 0.007142857142857143, 'infrastructure': 0.007142857142857143, 'data.': 0.0, 'that': 0.0, 'We': 0.0, 'users': 0.007142857142857143, 'several': 0.0, 'each': 0.0, 'successful': 0.0, 'name': 0.0, 'three': 0.0, 'let': 0.007142857142857143, 'challenge': 0.0, 'impacting': 0.0, 'predict': 0.0, 'penalized': 0.0, 'big': 0.0, 'insights': 0.0, 'expenses.': 0.0, \"don't\": 0.0, 'entire': 0.0, 'Watson': 0.0, 'labels.': 0.0, 'platform': 0.007142857142857143, 'attempt.\\n\\nThe': 0.0, 'it': 0.0, 'Instead,': 0.0, 'key': 0.0, 'we': 0.007142857142857143, 'post,': 0.0, 'two': 0.0, 'our': 0.0, 'webpage!\\n\\nSupervised': 0.0, 'AI': 0.007142857142857143, 'related': 0.0, 'modern': 0.0, 'code,': 0.0, 'see': 0.0, 'when': 0.0, 'now': 0.0, 'provisioning,': 0.007142857142857143, 'given': 0.0, 'science': 0.0, 'leaders': 0.0, 'that,': 0.0, 'techniques': 0.0, 'cloud': 0.007142857142857143, 'integrated': 0.007142857142857143, 'services.': 0.0, 'present.': 0.0, 'environment,': 0.0, 'pre-integrated': 0.0, 'mission.': 0.0, 'contribute': 0.0, 'different': 0.0, 'under': 0.0, 'capabilities,': 0.007142857142857143, 'multicloud': 0.014285714285714285, 'patterns,': 0.007142857142857143, 'implementation': 0.0, 'integration': 0.0, 'quickly,': 0.0, 'business.': 0.007142857142857143, 'everything': 0.0, 'with': 0.007142857142857143, 'attempt.\\n\\nUnsupervised': 0.0, 'To': 0.0, 'through': 0.0, 'helping': 0.0, 'securely': 0.007142857142857143, 'individual': 0.0, 'continuing': 0.0, 'end': 0.0, 'the': 0.05, 'find': 0.0, 'Machine': 0.0, 'information': 0.0, 'Service,': 0.0, 'array': 0.0, 'at': 0.0, 'came': 0.0, 'Service': 0.014285714285714285, 'lifecycle': 0.0, 'ultimate': 0.0, 'just': 0.0, 'reward': 0.0, 'lessons': 0.0, 'right': 0.007142857142857143, 'writers,': 0.0, 'flexible': 0.0, 'what': 0.0, 'questions.': 0.0, 'tries': 0.0, 'unknown.\\n\\nReinforcement': 0.0, 'advanced': 0.0, 'access': 0.0, 'set': 0.007142857142857143, 'areas': 0.0, 'Today,': 0.007142857142857143, 'organization': 0.0, 'cycle.\\nBuilding': 0.0, 'flows': 0.007142857142857143, 'visualization,': 0.0, 'release': 0.0, 'talent': 0.0, 'solution': 0.0, 'its': 0.0, 'across': 0.0, 'quiz': 0.0, '(features)': 0.0, 'initiatives.': 0.0, 'trained': 0.0, 'into': 0.0, 'industries': 0.0, 'discussion': 0.0, 'costly': 0.0, 'businesses': 0.0, 'nearly': 0.007142857142857143, 'A': 0.0, 'started': 0.007142857142857143, 'tell': 0.0, 'try': 0.0, 'framework': 0.0, 'delivery:': 0.0, 'IBM': 0.03571428571428571, 'These': 0.0, 'which': 0.0, 'needs': 0.007142857142857143, 'for': 0.02142857142857143, 'Knowledge': 0.0, 'site': 0.0, 'provide': 0.0, 'impart': 0.0, 'themselves': 0.0, 'available': 0.007142857142857143, 'throughout': 0.0, 'regarding': 0.0, 'Industry': 0.0, 'benefits': 0.0, 'blog': 0.0, 'test': 0.0, 'pain.\\nWe': 0.0, 'In': 0.0, 'learn': 0.0, 'analyze': 0.0, 'Get': 0.007142857142857143, 'either': 0.0, 'assets.\\nThis': 0.0, 'turn': 0.0, 'beginning': 0.0, 'hub': 0.0, 'as': 0.02142857142857143, 'deploying': 0.0, 'take': 0.007142857142857143, 'how': 0.0, 'unified': 0.0, 'designed': 0.0, 'experts': 0.0, 'can': 0.014285714285714285, 'starter': 0.007142857142857143, 'job': 0.0, 'clients': 0.0, 'introduce': 0.0, 'For': 0.0, 'must-have': 0.0, 'choice.': 0.0, 'from': 0.007142857142857143, '“new': 0.0, 'This': 0.0, 'evolve,': 0.007142857142857143, 'cohesively': 0.0, 'previous': 0.0, 'agent': 0.0, 'some': 0.0, 'infrastructure,': 0.0, 'looked': 0.0, 'even': 0.007142857142857143, 'are': 0.0, 'provision': 0.007142857142857143, 'an': 0.0, 'analytics': 0.0, 'foundation': 0.0, 'topics.': 0.0, 'we’ve': 0.0, 'Learning\\n\\nUnsupervised': 0.0, 'learning,': 0.0, 'answer.': 0.0, 'a': 0.02142857142857143, 'models,': 0.0, 'platform—and': 0.007142857142857143, 'fully': 0.007142857142857143, 'business': 0.0, 'life': 0.0, 'covers': 0.0, 'capabilities.': 0.0, 'label(s)': 0.0, '30,000': 0.0, 'about': 0.0, 'integrations': 0.007142857142857143, 'organize': 0.0, 'utilize': 0.007142857142857143, 'then': 0.0, 'being': 0.0, 'online': 0.0, 'while': 0.0, 'efficient': 0.0, 'was': 0.0, 'many': 0.0, 'considered': 0.0, 'board': 0.0, 'supplemental': 0.0, 'attributes': 0.0, 'also': 0.0, 'infuse': 0.0, 'have': 0.0, 'grow,': 0.007142857142857143, 'categories.': 0.0, 'fall': 0.0, 'give': 0.0, 'journey': 0.0, 'embed': 0.0, 'topics': 0.0, 'end,': 0.0, 'updates': 0.007142857142857143, 'processes': 0.007142857142857143, 'forum': 0.0, 'self-service': 0.0, 'your': 0.007142857142857143, 'minimizing': 0.0, 'bridges': 0.0, 'not': 0.0, 'less': 0.0, 'Science': 0.0, 'dataset': 0.0, 'share': 0.0, 'Data.': 0.0, 'rewarded': 0.0, 'below': 0.0, '(labels)': 0.0, 'structures': 0.0, 'From': 0.0, 'answers': 0.0, 'Catalog': 0.0, 'business-ready': 0.0, 'prescriptive': 0.0, 'among': 0.007142857142857143, 'found': 0.0, 'machine': 0.0, 'far': 0.0, 'underlying': 0.007142857142857143, 'breadth': 0.0, 'opportunities.': 0.0, 'collect,': 0.0, 'former': 0.0, 'interacting': 0.0, 'IT': 0.007142857142857143, 'Learning,': 0.0, 'both.': 0.0, 'At': 0.0, 'so': 0.007142857142857143, 'get': 0.0, 'attempts': 0.0, 'unique': 0.0, 'drag-and-drop': 0.0, 'hidden': 0.0, 'resource': 0.0, 'posts': 0.0, 'to': 0.02142857142857143, 'their': 0.0, 'forced': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5ySfhms4OVW",
        "outputId": "7f6d069f-1d07-4c56-fbbf-f82d5e2b0b17"
      },
      "source": [
        "print(term_freqE)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': 0.020512820512820513, 'understanding': 0.0, 'architecture': 0.0, '': 0.005128205128205128, 'this': 0.005128205128205128, 'required': 0.0, 'connect': 0.0, 'frequently,': 0.0, 'management': 0.010256410256410256, 'care': 0.0, 'maximize': 0.0, 'handle': 0.0, 'approach': 0.0, 'management,': 0.005128205128205128, 'COVID-19': 0.0, 'state': 0.005128205128205128, 'examples': 0.0, 'integrate': 0.005128205128205128, 'IBM,': 0.0, 'learns': 0.0, 'concerns': 0.0, 'real': 0.0, 'quickly': 0.0, 'case': 0.0, 'between': 0.0, 'resources,': 0.0, 'made': 0.0, 'Data,': 0.0, 'exponential': 0.0, 'platform.': 0.0, 'confront': 0.0, 'Ladder': 0.0, 'only': 0.0, 'add': 0.0, 'as-a-Service': 0.0, 'guided': 0.0, 'well': 0.005128205128205128, 'more': 0.0, 'has': 0.005128205128205128, 'organization.': 0.0, 'suggests': 0.0, 'engagements.': 0.0, 'algorithms': 0.0, '30': 0.0, 'tools,': 0.0, 'transform': 0.0, 'unsupervised': 0.0, 'services': 0.015384615384615385, 'redefine': 0.0, 'on': 0.0, 'Learning\\n\\nReinforcement': 0.0, 'It': 0.0, 'offer': 0.005128205128205128, 'you': 0.0, 'Service.': 0.0, 'services,': 0.005128205128205128, 'will': 0.0, 'Cloud.': 0.0, 'formalized': 0.0, 'trying': 0.0, 'problem.': 0.005128205128205128, 'DataOps': 0.015384615384615385, 'innovative': 0.0, 'Eliminate': 0.0, 'modernize': 0.0, 'continues': 0.0, 'technology,': 0.0, 'Pak': 0.02564102564102564, 'does': 0.0, 'day': 0.0, 'if': 0.005128205128205128, 'supervised': 0.0, 'planned,': 0.0, 'enterprise': 0.0, 'other': 0.010256410256410256, 'help': 0.010256410256410256, 'these': 0.0, 'address': 0.005128205128205128, 'community': 0.0, 'learned': 0.0, 'effectively': 0.005128205128205128, 'Central': 0.0, 'use': 0.0, 'analytics,': 0.0, 'normal.”': 0.0, 'digitally': 0.0, 'OpenScale,': 0.005128205128205128, 'succeed': 0.005128205128205128, 'leading': 0.0, 'environment.': 0.0, 'Studio,': 0.005128205128205128, 'depth': 0.005128205128205128, 'spanning': 0.005128205128205128, 'storage': 0.005128205128205128, 'sources,': 0.0, 'or': 0.0, 'many,': 0.0, 'over': 0.0, 'latter': 0.005128205128205128, 'challenges': 0.0, 'model': 0.0, 'focus': 0.0, 'exactly': 0.0, 'ML,': 0.0, 'own': 0.0, 'understand': 0.0, 'be': 0.005128205128205128, 'wide': 0.0, 'AI,': 0.0, 'include': 0.005128205128205128, 'of': 0.020512820512820513, 'aspirations': 0.0, 'initial': 0.005128205128205128, 'value': 0.0, 'contributing': 0.0, 'Cloud': 0.02564102564102564, 'tighter': 0.0, 'want': 0.005128205128205128, 'The': 0.0, 'Give': 0.0, 'including': 0.005128205128205128, 'governance': 0.005128205128205128, 'reinforcement': 0.0, 'results.': 0.0, 'hand,': 0.0, 'learn.': 0.0, 'framework,': 0.0, 'managed': 0.0, 'ingestion': 0.005128205128205128, 'and': 0.03076923076923077, 'Data': 0.020512820512820513, 'methodology': 0.0, '2018,': 0.0, 'provides': 0.005128205128205128, 'entry': 0.0, 'offers': 0.0, 'developed': 0.0, 'Learning\\n\\nIn': 0.0, 'faster': 0.0, 'than': 0.0, 'labels': 0.0, 'is': 0.005128205128205128, 'acts': 0.0, 'beginning.': 0.0, 'knowledge': 0.0, 'today.': 0.0, 'learning': 0.0, 'both': 0.0, 'scale': 0.0, 'in': 0.010256410256410256, 'full': 0.005128205128205128, 'cloud.': 0.0, 'includes': 0.010256410256410256, 'originally': 0.0, 'where': 0.0, 'barriers': 0.0, 'As': 0.0, 'infrastructure': 0.0, 'data.': 0.0, 'that': 0.005128205128205128, 'We': 0.005128205128205128, 'users': 0.0, 'several': 0.005128205128205128, 'each': 0.0, 'successful': 0.0, 'name': 0.0, 'three': 0.0, 'let': 0.0, 'challenge': 0.005128205128205128, 'impacting': 0.0, 'predict': 0.0, 'penalized': 0.0, 'big': 0.0, 'insights': 0.0, 'expenses.': 0.0, \"don't\": 0.0, 'entire': 0.0, 'Watson': 0.02564102564102564, 'labels.': 0.0, 'platform': 0.0, 'attempt.\\n\\nThe': 0.0, 'it': 0.0, 'Instead,': 0.0, 'key': 0.005128205128205128, 'we': 0.0, 'post,': 0.0, 'two': 0.0, 'our': 0.0, 'webpage!\\n\\nSupervised': 0.0, 'AI': 0.020512820512820513, 'related': 0.0, 'modern': 0.005128205128205128, 'code,': 0.0, 'see': 0.010256410256410256, 'when': 0.0, 'now': 0.0, 'provisioning,': 0.0, 'given': 0.0, 'science': 0.0, 'leaders': 0.0, 'that,': 0.0, 'techniques': 0.0, 'cloud': 0.010256410256410256, 'integrated': 0.0, 'services.': 0.005128205128205128, 'present.': 0.0, 'environment,': 0.0, 'pre-integrated': 0.005128205128205128, 'mission.': 0.005128205128205128, 'contribute': 0.0, 'different': 0.0, 'under': 0.0, 'capabilities,': 0.0, 'multicloud': 0.0, 'patterns,': 0.0, 'implementation': 0.0, 'integration': 0.0, 'quickly,': 0.005128205128205128, 'business.': 0.0, 'everything': 0.0, 'with': 0.015384615384615385, 'attempt.\\n\\nUnsupervised': 0.0, 'To': 0.005128205128205128, 'through': 0.0, 'helping': 0.0, 'securely': 0.0, 'individual': 0.005128205128205128, 'continuing': 0.0, 'end': 0.005128205128205128, 'the': 0.03076923076923077, 'find': 0.0, 'Machine': 0.005128205128205128, 'information': 0.0, 'Service,': 0.005128205128205128, 'array': 0.0, 'at': 0.0, 'came': 0.0, 'Service': 0.015384615384615385, 'lifecycle': 0.005128205128205128, 'ultimate': 0.005128205128205128, 'just': 0.005128205128205128, 'reward': 0.0, 'lessons': 0.0, 'right': 0.0, 'writers,': 0.0, 'flexible': 0.0, 'what': 0.005128205128205128, 'questions.': 0.0, 'tries': 0.0, 'unknown.\\n\\nReinforcement': 0.0, 'advanced': 0.0, 'access': 0.005128205128205128, 'set': 0.010256410256410256, 'areas': 0.0, 'Today,': 0.0, 'organization': 0.0, 'cycle.\\nBuilding': 0.0, 'flows': 0.0, 'visualization,': 0.0, 'release': 0.005128205128205128, 'talent': 0.0, 'solution': 0.0, 'its': 0.0, 'across': 0.0, 'quiz': 0.0, '(features)': 0.0, 'initiatives.': 0.005128205128205128, 'trained': 0.0, 'into': 0.0, 'industries': 0.0, 'discussion': 0.0, 'costly': 0.0, 'businesses': 0.015384615384615385, 'nearly': 0.0, 'A': 0.0, 'started': 0.005128205128205128, 'tell': 0.0, 'try': 0.0, 'framework': 0.0, 'delivery:': 0.0, 'IBM': 0.03076923076923077, 'These': 0.010256410256410256, 'which': 0.0, 'needs': 0.0, 'for': 0.041025641025641026, 'Knowledge': 0.010256410256410256, 'site': 0.0, 'provide': 0.0, 'impart': 0.0, 'themselves': 0.0, 'available': 0.0, 'throughout': 0.0, 'regarding': 0.0, 'Industry': 0.0, 'benefits': 0.0, 'blog': 0.0, 'test': 0.0, 'pain.\\nWe': 0.005128205128205128, 'In': 0.0, 'learn': 0.0, 'analyze': 0.0, 'Get': 0.0, 'either': 0.0, 'assets.\\nThis': 0.005128205128205128, 'turn': 0.0, 'beginning': 0.005128205128205128, 'hub': 0.0, 'as': 0.041025641025641026, 'deploying': 0.0, 'take': 0.0, 'how': 0.0, 'unified': 0.0, 'designed': 0.0, 'experts': 0.0, 'can': 0.010256410256410256, 'starter': 0.005128205128205128, 'job': 0.0, 'clients': 0.0, 'introduce': 0.0, 'For': 0.0, 'must-have': 0.005128205128205128, 'choice.': 0.0, 'from': 0.0, '“new': 0.0, 'This': 0.0, 'evolve,': 0.0, 'cohesively': 0.005128205128205128, 'previous': 0.0, 'agent': 0.0, 'some': 0.0, 'infrastructure,': 0.0, 'looked': 0.0, 'even': 0.0, 'are': 0.0, 'provision': 0.0, 'an': 0.005128205128205128, 'analytics': 0.0, 'foundation': 0.005128205128205128, 'topics.': 0.0, 'we’ve': 0.0, 'Learning\\n\\nUnsupervised': 0.0, 'learning,': 0.0, 'answer.': 0.0, 'a': 0.046153846153846156, 'models,': 0.0, 'platform—and': 0.0, 'fully': 0.0, 'business': 0.0, 'life': 0.0, 'covers': 0.0, 'capabilities.': 0.0, 'label(s)': 0.0, '30,000': 0.0, 'about': 0.0, 'integrations': 0.0, 'organize': 0.0, 'utilize': 0.0, 'then': 0.0, 'being': 0.005128205128205128, 'online': 0.0, 'while': 0.005128205128205128, 'efficient': 0.005128205128205128, 'was': 0.0, 'many': 0.0, 'considered': 0.005128205128205128, 'board': 0.0, 'supplemental': 0.005128205128205128, 'attributes': 0.0, 'also': 0.0, 'infuse': 0.0, 'have': 0.0, 'grow,': 0.0, 'categories.': 0.0, 'fall': 0.0, 'give': 0.0, 'journey': 0.005128205128205128, 'embed': 0.0, 'topics': 0.0, 'end,': 0.005128205128205128, 'updates': 0.0, 'processes': 0.0, 'forum': 0.0, 'self-service': 0.005128205128205128, 'your': 0.0, 'minimizing': 0.0, 'bridges': 0.0, 'not': 0.0, 'less': 0.005128205128205128, 'Science': 0.0, 'dataset': 0.0, 'share': 0.0, 'Data.': 0.005128205128205128, 'rewarded': 0.0, 'below': 0.0, '(labels)': 0.0, 'structures': 0.0, 'From': 0.0, 'answers': 0.0, 'Catalog': 0.010256410256410256, 'business-ready': 0.005128205128205128, 'prescriptive': 0.0, 'among': 0.0, 'found': 0.0, 'machine': 0.0, 'far': 0.0, 'underlying': 0.0, 'breadth': 0.005128205128205128, 'opportunities.': 0.0, 'collect,': 0.0, 'former': 0.005128205128205128, 'interacting': 0.0, 'IT': 0.0, 'Learning,': 0.005128205128205128, 'both.': 0.005128205128205128, 'At': 0.0, 'so': 0.0, 'get': 0.005128205128205128, 'attempts': 0.0, 'unique': 0.0, 'drag-and-drop': 0.0, 'hidden': 0.0, 'resource': 0.0, 'posts': 0.0, 'to': 0.020512820512820513, 'their': 0.005128205128205128, 'forced': 0.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCAB4dGI4xMu"
      },
      "source": [
        "### Inverse Data Frequency (IDF)\n",
        "The log of the number of documents divided by the number of documents that contain the word w."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9WnbfPZ40zi"
      },
      "source": [
        "def computeIDF(documents):\n",
        "    import math\n",
        "    N = len(documents)\n",
        "    \n",
        "    idfDict = dict.fromkeys(documents[0].keys(), 0)\n",
        "    for document in documents:\n",
        "        for word, val in document.items():\n",
        "            if val > 0:\n",
        "                idfDict[word] += 1\n",
        "    \n",
        "    for word, val in idfDict.items():\n",
        "        idfDict[word] = math.log(N / float(val))\n",
        "    return idfDict"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMHrxs-u43fE",
        "outputId": "ff73ddc0-8875-460e-cd19-8c83cc3c3891"
      },
      "source": [
        "idfs = computeIDF([numOfWordsA, numOfWordsB, numOfWordsC, numOfWordsD, numOfWordsE])\n",
        "print(idfs)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'data': 0.22314355131420976, 'understanding': 1.6094379124341003, 'architecture': 1.6094379124341003, '': 0.9162907318741551, 'this': 0.22314355131420976, 'required': 0.9162907318741551, 'connect': 1.6094379124341003, 'frequently,': 1.6094379124341003, 'management': 0.9162907318741551, 'care': 1.6094379124341003, 'maximize': 1.6094379124341003, 'handle': 1.6094379124341003, 'approach': 1.6094379124341003, 'management,': 1.6094379124341003, 'COVID-19': 1.6094379124341003, 'state': 1.6094379124341003, 'examples': 1.6094379124341003, 'integrate': 1.6094379124341003, 'IBM,': 1.6094379124341003, 'learns': 1.6094379124341003, 'concerns': 1.6094379124341003, 'real': 1.6094379124341003, 'quickly': 1.6094379124341003, 'case': 1.6094379124341003, 'between': 1.6094379124341003, 'resources,': 1.6094379124341003, 'made': 1.6094379124341003, 'Data,': 1.6094379124341003, 'exponential': 1.6094379124341003, 'platform.': 1.6094379124341003, 'confront': 1.6094379124341003, 'Ladder': 1.6094379124341003, 'only': 1.6094379124341003, 'add': 1.6094379124341003, 'as-a-Service': 1.6094379124341003, 'guided': 1.6094379124341003, 'well': 0.9162907318741551, 'more': 1.6094379124341003, 'has': 1.6094379124341003, 'organization.': 1.6094379124341003, 'suggests': 1.6094379124341003, 'engagements.': 1.6094379124341003, 'algorithms': 1.6094379124341003, '30': 1.6094379124341003, 'tools,': 0.9162907318741551, 'transform': 1.6094379124341003, 'unsupervised': 1.6094379124341003, 'services': 0.5108256237659907, 'redefine': 1.6094379124341003, 'on': 0.5108256237659907, 'Learning\\n\\nReinforcement': 1.6094379124341003, 'It': 1.6094379124341003, 'offer': 0.9162907318741551, 'you': 0.5108256237659907, 'Service.': 1.6094379124341003, 'services,': 0.9162907318741551, 'will': 0.9162907318741551, 'Cloud.': 1.6094379124341003, 'formalized': 1.6094379124341003, 'trying': 1.6094379124341003, 'problem.': 1.6094379124341003, 'DataOps': 1.6094379124341003, 'innovative': 1.6094379124341003, 'Eliminate': 1.6094379124341003, 'modernize': 1.6094379124341003, 'continues': 1.6094379124341003, 'technology,': 1.6094379124341003, 'Pak': 0.5108256237659907, 'does': 0.9162907318741551, 'day': 1.6094379124341003, 'if': 1.6094379124341003, 'supervised': 1.6094379124341003, 'planned,': 1.6094379124341003, 'enterprise': 1.6094379124341003, 'other': 0.5108256237659907, 'help': 0.9162907318741551, 'these': 1.6094379124341003, 'address': 0.9162907318741551, 'community': 1.6094379124341003, 'learned': 1.6094379124341003, 'effectively': 1.6094379124341003, 'Central': 1.6094379124341003, 'use': 1.6094379124341003, 'analytics,': 1.6094379124341003, 'normal.”': 1.6094379124341003, 'digitally': 1.6094379124341003, 'OpenScale,': 1.6094379124341003, 'succeed': 1.6094379124341003, 'leading': 1.6094379124341003, 'environment.': 1.6094379124341003, 'Studio,': 1.6094379124341003, 'depth': 1.6094379124341003, 'spanning': 0.9162907318741551, 'storage': 1.6094379124341003, 'sources,': 1.6094379124341003, 'or': 0.9162907318741551, 'many,': 1.6094379124341003, 'over': 1.6094379124341003, 'latter': 1.6094379124341003, 'challenges': 0.9162907318741551, 'model': 1.6094379124341003, 'focus': 1.6094379124341003, 'exactly': 1.6094379124341003, 'ML,': 1.6094379124341003, 'own': 1.6094379124341003, 'understand': 1.6094379124341003, 'be': 0.9162907318741551, 'wide': 1.6094379124341003, 'AI,': 1.6094379124341003, 'include': 0.9162907318741551, 'of': 0.0, 'aspirations': 1.6094379124341003, 'initial': 1.6094379124341003, 'value': 1.6094379124341003, 'contributing': 1.6094379124341003, 'Cloud': 0.5108256237659907, 'tighter': 1.6094379124341003, 'want': 1.6094379124341003, 'The': 0.9162907318741551, 'Give': 1.6094379124341003, 'including': 0.9162907318741551, 'governance': 0.9162907318741551, 'reinforcement': 1.6094379124341003, 'results.': 1.6094379124341003, 'hand,': 1.6094379124341003, 'learn.': 1.6094379124341003, 'framework,': 1.6094379124341003, 'managed': 1.6094379124341003, 'ingestion': 1.6094379124341003, 'and': 0.0, 'Data': 0.22314355131420976, 'methodology': 1.6094379124341003, '2018,': 1.6094379124341003, 'provides': 0.5108256237659907, 'entry': 1.6094379124341003, 'offers': 1.6094379124341003, 'developed': 1.6094379124341003, 'Learning\\n\\nIn': 1.6094379124341003, 'faster': 1.6094379124341003, 'than': 1.6094379124341003, 'labels': 1.6094379124341003, 'is': 0.22314355131420976, 'acts': 1.6094379124341003, 'beginning.': 1.6094379124341003, 'knowledge': 1.6094379124341003, 'today.': 1.6094379124341003, 'learning': 1.6094379124341003, 'both': 1.6094379124341003, 'scale': 1.6094379124341003, 'in': 0.9162907318741551, 'full': 1.6094379124341003, 'cloud.': 1.6094379124341003, 'includes': 1.6094379124341003, 'originally': 1.6094379124341003, 'where': 1.6094379124341003, 'barriers': 1.6094379124341003, 'As': 1.6094379124341003, 'infrastructure': 1.6094379124341003, 'data.': 1.6094379124341003, 'that': 0.5108256237659907, 'We': 0.9162907318741551, 'users': 1.6094379124341003, 'several': 1.6094379124341003, 'each': 1.6094379124341003, 'successful': 1.6094379124341003, 'name': 1.6094379124341003, 'three': 1.6094379124341003, 'let': 1.6094379124341003, 'challenge': 0.9162907318741551, 'impacting': 1.6094379124341003, 'predict': 1.6094379124341003, 'penalized': 1.6094379124341003, 'big': 1.6094379124341003, 'insights': 1.6094379124341003, 'expenses.': 1.6094379124341003, \"don't\": 1.6094379124341003, 'entire': 1.6094379124341003, 'Watson': 1.6094379124341003, 'labels.': 1.6094379124341003, 'platform': 0.9162907318741551, 'attempt.\\n\\nThe': 1.6094379124341003, 'it': 0.9162907318741551, 'Instead,': 1.6094379124341003, 'key': 0.5108256237659907, 'we': 0.5108256237659907, 'post,': 1.6094379124341003, 'two': 1.6094379124341003, 'our': 1.6094379124341003, 'webpage!\\n\\nSupervised': 1.6094379124341003, 'AI': 0.5108256237659907, 'related': 1.6094379124341003, 'modern': 1.6094379124341003, 'code,': 1.6094379124341003, 'see': 1.6094379124341003, 'when': 0.9162907318741551, 'now': 1.6094379124341003, 'provisioning,': 1.6094379124341003, 'given': 1.6094379124341003, 'science': 1.6094379124341003, 'leaders': 1.6094379124341003, 'that,': 1.6094379124341003, 'techniques': 1.6094379124341003, 'cloud': 0.5108256237659907, 'integrated': 0.9162907318741551, 'services.': 1.6094379124341003, 'present.': 1.6094379124341003, 'environment,': 1.6094379124341003, 'pre-integrated': 1.6094379124341003, 'mission.': 1.6094379124341003, 'contribute': 1.6094379124341003, 'different': 1.6094379124341003, 'under': 1.6094379124341003, 'capabilities,': 1.6094379124341003, 'multicloud': 1.6094379124341003, 'patterns,': 1.6094379124341003, 'implementation': 1.6094379124341003, 'integration': 1.6094379124341003, 'quickly,': 1.6094379124341003, 'business.': 1.6094379124341003, 'everything': 1.6094379124341003, 'with': 0.22314355131420976, 'attempt.\\n\\nUnsupervised': 1.6094379124341003, 'To': 1.6094379124341003, 'through': 1.6094379124341003, 'helping': 1.6094379124341003, 'securely': 1.6094379124341003, 'individual': 1.6094379124341003, 'continuing': 1.6094379124341003, 'end': 1.6094379124341003, 'the': 0.22314355131420976, 'find': 1.6094379124341003, 'Machine': 0.9162907318741551, 'information': 1.6094379124341003, 'Service,': 1.6094379124341003, 'array': 1.6094379124341003, 'at': 1.6094379124341003, 'came': 1.6094379124341003, 'Service': 0.9162907318741551, 'lifecycle': 1.6094379124341003, 'ultimate': 1.6094379124341003, 'just': 0.9162907318741551, 'reward': 1.6094379124341003, 'lessons': 1.6094379124341003, 'right': 1.6094379124341003, 'writers,': 1.6094379124341003, 'flexible': 1.6094379124341003, 'what': 0.5108256237659907, 'questions.': 1.6094379124341003, 'tries': 1.6094379124341003, 'unknown.\\n\\nReinforcement': 1.6094379124341003, 'advanced': 1.6094379124341003, 'access': 1.6094379124341003, 'set': 0.9162907318741551, 'areas': 1.6094379124341003, 'Today,': 1.6094379124341003, 'organization': 1.6094379124341003, 'cycle.\\nBuilding': 1.6094379124341003, 'flows': 1.6094379124341003, 'visualization,': 1.6094379124341003, 'release': 1.6094379124341003, 'talent': 1.6094379124341003, 'solution': 1.6094379124341003, 'its': 0.9162907318741551, 'across': 1.6094379124341003, 'quiz': 1.6094379124341003, '(features)': 1.6094379124341003, 'initiatives.': 1.6094379124341003, 'trained': 1.6094379124341003, 'into': 0.9162907318741551, 'industries': 1.6094379124341003, 'discussion': 1.6094379124341003, 'costly': 1.6094379124341003, 'businesses': 1.6094379124341003, 'nearly': 0.9162907318741551, 'A': 1.6094379124341003, 'started': 0.9162907318741551, 'tell': 1.6094379124341003, 'try': 1.6094379124341003, 'framework': 1.6094379124341003, 'delivery:': 1.6094379124341003, 'IBM': 0.5108256237659907, 'These': 1.6094379124341003, 'which': 1.6094379124341003, 'needs': 0.9162907318741551, 'for': 0.0, 'Knowledge': 1.6094379124341003, 'site': 1.6094379124341003, 'provide': 1.6094379124341003, 'impart': 1.6094379124341003, 'themselves': 1.6094379124341003, 'available': 1.6094379124341003, 'throughout': 1.6094379124341003, 'regarding': 1.6094379124341003, 'Industry': 1.6094379124341003, 'benefits': 1.6094379124341003, 'blog': 1.6094379124341003, 'test': 1.6094379124341003, 'pain.\\nWe': 1.6094379124341003, 'In': 0.9162907318741551, 'learn': 1.6094379124341003, 'analyze': 1.6094379124341003, 'Get': 1.6094379124341003, 'either': 1.6094379124341003, 'assets.\\nThis': 1.6094379124341003, 'turn': 1.6094379124341003, 'beginning': 1.6094379124341003, 'hub': 1.6094379124341003, 'as': 0.22314355131420976, 'deploying': 1.6094379124341003, 'take': 1.6094379124341003, 'how': 0.9162907318741551, 'unified': 1.6094379124341003, 'designed': 1.6094379124341003, 'experts': 1.6094379124341003, 'can': 0.22314355131420976, 'starter': 0.9162907318741551, 'job': 1.6094379124341003, 'clients': 1.6094379124341003, 'introduce': 1.6094379124341003, 'For': 1.6094379124341003, 'must-have': 1.6094379124341003, 'choice.': 1.6094379124341003, 'from': 0.5108256237659907, '“new': 1.6094379124341003, 'This': 1.6094379124341003, 'evolve,': 1.6094379124341003, 'cohesively': 1.6094379124341003, 'previous': 1.6094379124341003, 'agent': 1.6094379124341003, 'some': 1.6094379124341003, 'infrastructure,': 1.6094379124341003, 'looked': 1.6094379124341003, 'even': 0.9162907318741551, 'are': 0.9162907318741551, 'provision': 1.6094379124341003, 'an': 0.22314355131420976, 'analytics': 1.6094379124341003, 'foundation': 0.9162907318741551, 'topics.': 1.6094379124341003, 'we’ve': 1.6094379124341003, 'Learning\\n\\nUnsupervised': 1.6094379124341003, 'learning,': 1.6094379124341003, 'answer.': 1.6094379124341003, 'a': 0.0, 'models,': 1.6094379124341003, 'platform—and': 1.6094379124341003, 'fully': 1.6094379124341003, 'business': 1.6094379124341003, 'life': 1.6094379124341003, 'covers': 1.6094379124341003, 'capabilities.': 1.6094379124341003, 'label(s)': 1.6094379124341003, '30,000': 1.6094379124341003, 'about': 1.6094379124341003, 'integrations': 1.6094379124341003, 'organize': 1.6094379124341003, 'utilize': 1.6094379124341003, 'then': 1.6094379124341003, 'being': 1.6094379124341003, 'online': 1.6094379124341003, 'while': 0.5108256237659907, 'efficient': 1.6094379124341003, 'was': 1.6094379124341003, 'many': 1.6094379124341003, 'considered': 1.6094379124341003, 'board': 1.6094379124341003, 'supplemental': 1.6094379124341003, 'attributes': 1.6094379124341003, 'also': 0.9162907318741551, 'infuse': 1.6094379124341003, 'have': 1.6094379124341003, 'grow,': 1.6094379124341003, 'categories.': 1.6094379124341003, 'fall': 1.6094379124341003, 'give': 1.6094379124341003, 'journey': 1.6094379124341003, 'embed': 1.6094379124341003, 'topics': 1.6094379124341003, 'end,': 1.6094379124341003, 'updates': 0.9162907318741551, 'processes': 1.6094379124341003, 'forum': 1.6094379124341003, 'self-service': 1.6094379124341003, 'your': 0.5108256237659907, 'minimizing': 1.6094379124341003, 'bridges': 1.6094379124341003, 'not': 1.6094379124341003, 'less': 1.6094379124341003, 'Science': 1.6094379124341003, 'dataset': 1.6094379124341003, 'share': 1.6094379124341003, 'Data.': 1.6094379124341003, 'rewarded': 1.6094379124341003, 'below': 1.6094379124341003, '(labels)': 1.6094379124341003, 'structures': 1.6094379124341003, 'From': 1.6094379124341003, 'answers': 1.6094379124341003, 'Catalog': 1.6094379124341003, 'business-ready': 1.6094379124341003, 'prescriptive': 1.6094379124341003, 'among': 1.6094379124341003, 'found': 1.6094379124341003, 'machine': 1.6094379124341003, 'far': 1.6094379124341003, 'underlying': 1.6094379124341003, 'breadth': 1.6094379124341003, 'opportunities.': 1.6094379124341003, 'collect,': 1.6094379124341003, 'former': 1.6094379124341003, 'interacting': 1.6094379124341003, 'IT': 0.9162907318741551, 'Learning,': 1.6094379124341003, 'both.': 1.6094379124341003, 'At': 1.6094379124341003, 'so': 0.9162907318741551, 'get': 1.6094379124341003, 'attempts': 1.6094379124341003, 'unique': 1.6094379124341003, 'drag-and-drop': 1.6094379124341003, 'hidden': 1.6094379124341003, 'resource': 1.6094379124341003, 'posts': 1.6094379124341003, 'to': 0.0, 'their': 1.6094379124341003, 'forced': 1.6094379124341003}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvzD5xoB4_OE"
      },
      "source": [
        "### a. Top TF-IDF words for the above input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuaSzfxd46Pq"
      },
      "source": [
        "def computeTFIDF(tfBagOfWords, idfs):\n",
        "    tfidf = {}\n",
        "    for word, val in tfBagOfWords.items():\n",
        "        tfidf[word] = val * idfs[word]\n",
        "    return tfidf"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "5Gq8y9If5N8I",
        "outputId": "b2f3bfca-7a5c-4f19-b035-deaeb6abfda1"
      },
      "source": [
        "tfidfA = computeTFIDF(tfA, idfs)\n",
        "tfidfB = computeTFIDF(tfB, idfs)\n",
        "tfidfC = computeTFIDF(tfC, idfs)\n",
        "tfidfD = computeTFIDF(tfD, idfs)\n",
        "tfidfE = computeTFIDF(tfE, idfs)\n",
        "df = pd.DataFrame([tfidfA, tfidfB, tfidfC, tfidfD, tfidfE])\n",
        "df"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>understanding</th>\n",
              "      <th>architecture</th>\n",
              "      <th></th>\n",
              "      <th>this</th>\n",
              "      <th>required</th>\n",
              "      <th>connect</th>\n",
              "      <th>frequently,</th>\n",
              "      <th>management</th>\n",
              "      <th>care</th>\n",
              "      <th>maximize</th>\n",
              "      <th>handle</th>\n",
              "      <th>approach</th>\n",
              "      <th>management,</th>\n",
              "      <th>COVID-19</th>\n",
              "      <th>state</th>\n",
              "      <th>examples</th>\n",
              "      <th>integrate</th>\n",
              "      <th>IBM,</th>\n",
              "      <th>learns</th>\n",
              "      <th>concerns</th>\n",
              "      <th>real</th>\n",
              "      <th>quickly</th>\n",
              "      <th>case</th>\n",
              "      <th>between</th>\n",
              "      <th>resources,</th>\n",
              "      <th>made</th>\n",
              "      <th>Data,</th>\n",
              "      <th>exponential</th>\n",
              "      <th>platform.</th>\n",
              "      <th>confront</th>\n",
              "      <th>Ladder</th>\n",
              "      <th>only</th>\n",
              "      <th>add</th>\n",
              "      <th>as-a-Service</th>\n",
              "      <th>guided</th>\n",
              "      <th>well</th>\n",
              "      <th>more</th>\n",
              "      <th>has</th>\n",
              "      <th>organization.</th>\n",
              "      <th>...</th>\n",
              "      <th>not</th>\n",
              "      <th>less</th>\n",
              "      <th>Science</th>\n",
              "      <th>dataset</th>\n",
              "      <th>share</th>\n",
              "      <th>Data.</th>\n",
              "      <th>rewarded</th>\n",
              "      <th>below</th>\n",
              "      <th>(labels)</th>\n",
              "      <th>structures</th>\n",
              "      <th>From</th>\n",
              "      <th>answers</th>\n",
              "      <th>Catalog</th>\n",
              "      <th>business-ready</th>\n",
              "      <th>prescriptive</th>\n",
              "      <th>among</th>\n",
              "      <th>found</th>\n",
              "      <th>machine</th>\n",
              "      <th>far</th>\n",
              "      <th>underlying</th>\n",
              "      <th>breadth</th>\n",
              "      <th>opportunities.</th>\n",
              "      <th>collect,</th>\n",
              "      <th>former</th>\n",
              "      <th>interacting</th>\n",
              "      <th>IT</th>\n",
              "      <th>Learning,</th>\n",
              "      <th>both.</th>\n",
              "      <th>At</th>\n",
              "      <th>so</th>\n",
              "      <th>get</th>\n",
              "      <th>attempts</th>\n",
              "      <th>unique</th>\n",
              "      <th>drag-and-drop</th>\n",
              "      <th>hidden</th>\n",
              "      <th>resource</th>\n",
              "      <th>posts</th>\n",
              "      <th>to</th>\n",
              "      <th>their</th>\n",
              "      <th>forced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.008368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020118</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020118</td>\n",
              "      <td>0.020118</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001290</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.018606</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.018606</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.037212</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005296</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.009303</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002755</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002755</td>\n",
              "      <td>0.003771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.004782</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006545</td>\n",
              "      <td>0.001594</td>\n",
              "      <td>0.006545</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013090</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.022992</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011496</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006545</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004577</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004699</td>\n",
              "      <td>0.001144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.009398</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004699</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016507</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 426 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       data  understanding  architecture  ...   to     their    forced\n",
              "0  0.008368       0.000000      0.000000  ...  0.0  0.000000  0.000000\n",
              "1  0.000000       0.009303      0.000000  ...  0.0  0.000000  0.000000\n",
              "2  0.002755       0.000000      0.006623  ...  0.0  0.000000  0.006623\n",
              "3  0.004782       0.000000      0.000000  ...  0.0  0.000000  0.000000\n",
              "4  0.004577       0.000000      0.000000  ...  0.0  0.008254  0.000000\n",
              "\n",
              "[5 rows x 426 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tcM44IW16dAs"
      },
      "source": [
        "### b. TF-IDF words for the lemmatized input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "km72UjDG5RYd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e4f87d3-06d5-4f81-ffc8-cacb7b28bd94"
      },
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7oY2OeV6gpf"
      },
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "word_listA = nltk.word_tokenize(documentA)\n",
        "word_listB = nltk.word_tokenize(documentB)\n",
        "word_listC = nltk.word_tokenize(documentC)\n",
        "word_listD = nltk.word_tokenize(documentD)\n",
        "word_listE = nltk.word_tokenize(documentE)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6cgYQWFk6iWg"
      },
      "source": [
        "# Lemmatizing all 5 text files\n",
        "lemmatized_documentA = ' '.join([lemmatizer.lemmatize(w) for w in word_listA])\n",
        "lemmatized_documentB = ' '.join([lemmatizer.lemmatize(w) for w in word_listB])\n",
        "lemmatized_documentC = ' '.join([lemmatizer.lemmatize(w) for w in word_listC])\n",
        "lemmatized_documentD = ' '.join([lemmatizer.lemmatize(w) for w in word_listD])\n",
        "lemmatized_documentE = ' '.join([lemmatizer.lemmatize(w) for w in word_listE])"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Fegu8St6oYW"
      },
      "source": [
        "# Splitting string into words\n",
        "lbagOfWordsA = lemmatized_documentA.split(' ')\n",
        "lbagOfWordsB = lemmatized_documentB.split(' ')\n",
        "lbagOfWordsC = lemmatized_documentC.split(' ')\n",
        "lbagOfWordsD = lemmatized_documentD.split(' ')\n",
        "lbagOfWordsE = lemmatized_documentE.split(' ')"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEAD6mV16tp3",
        "outputId": "a0e6d61f-2712-4a3e-9fb5-ee65f53ac326"
      },
      "source": [
        "# Selecting only unique words\n",
        "luniqueWords = set(lbagOfWordsA).union(set(lbagOfWordsB)).union(set(lbagOfWordsC)).union(set(lbagOfWordsD)).union(set(lbagOfWordsE))\n",
        "len(luniqueWords)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BkI8GurL6zoC"
      },
      "source": [
        "# Creating dictionary of words\n",
        "\n",
        "lnumOfWordsA = dict.fromkeys(luniqueWords, 0)\n",
        "for word in lbagOfWordsA:\n",
        "    lnumOfWordsA[word] += 1\n",
        "lnumOfWordsB = dict.fromkeys(luniqueWords, 0)\n",
        "for word in lbagOfWordsB:\n",
        "    lnumOfWordsB[word] += 1\n",
        "lnumOfWordsC = dict.fromkeys(luniqueWords, 0)\n",
        "for word in lbagOfWordsC:\n",
        "    lnumOfWordsC[word] += 1\n",
        "lnumOfWordsD = dict.fromkeys(luniqueWords, 0)\n",
        "for word in lbagOfWordsD:\n",
        "    lnumOfWordsD[word] += 1\n",
        "lnumOfWordsE = dict.fromkeys(luniqueWords, 0)\n",
        "for word in lbagOfWordsE:\n",
        "    lnumOfWordsE[word] += 1"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RX6ZeAAN62ON"
      },
      "source": [
        "ltfA = computeTF(lnumOfWordsA, lbagOfWordsA)\n",
        "ltfB = computeTF(lnumOfWordsB, lbagOfWordsB)\n",
        "ltfC = computeTF(lnumOfWordsC, lbagOfWordsC)\n",
        "ltfD = computeTF(lnumOfWordsD, lbagOfWordsD)\n",
        "ltfE = computeTF(lnumOfWordsE, lbagOfWordsE)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWCAJhj_64tf"
      },
      "source": [
        "lidfs = computeIDF([lnumOfWordsA, lnumOfWordsB, lnumOfWordsC, lnumOfWordsD, lnumOfWordsE])\n"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "K08gRYjy66HU",
        "outputId": "f05bbf54-b6b8-4a72-e6f3-1828917ef9d4"
      },
      "source": [
        "# Calculating the TFIDF\n",
        "ltfidfA = computeTFIDF(ltfA, lidfs)\n",
        "ltfidfB = computeTFIDF(ltfB, lidfs)\n",
        "ltfidfC = computeTFIDF(ltfC, lidfs)\n",
        "ltfidfD = computeTFIDF(ltfD, lidfs)\n",
        "ltfidfE = computeTFIDF(ltfE, lidfs)\n",
        "ldf = pd.DataFrame([ltfidfA, ltfidfB, ltfidfC, ltfidfD, ltfidfE])\n",
        "ldf"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>data</th>\n",
              "      <th>understanding</th>\n",
              "      <th>architecture</th>\n",
              "      <th>this</th>\n",
              "      <th>flow</th>\n",
              "      <th>required</th>\n",
              "      <th>connect</th>\n",
              "      <th>do</th>\n",
              "      <th>management</th>\n",
              "      <th>Learning</th>\n",
              "      <th>care</th>\n",
              "      <th>maximize</th>\n",
              "      <th>:</th>\n",
              "      <th>handle</th>\n",
              "      <th>provisioning</th>\n",
              "      <th>structure</th>\n",
              "      <th>approach</th>\n",
              "      <th>COVID-19</th>\n",
              "      <th>state</th>\n",
              "      <th>topic</th>\n",
              "      <th>writer</th>\n",
              "      <th>integrate</th>\n",
              "      <th>learns</th>\n",
              "      <th>real</th>\n",
              "      <th>quickly</th>\n",
              "      <th>tool</th>\n",
              "      <th>present</th>\n",
              "      <th>case</th>\n",
              "      <th>between</th>\n",
              "      <th>aspiration</th>\n",
              "      <th>made</th>\n",
              "      <th>exponential</th>\n",
              "      <th>evolve</th>\n",
              "      <th>confront</th>\n",
              "      <th>Ladder</th>\n",
              "      <th>only</th>\n",
              "      <th>add</th>\n",
              "      <th>as-a-Service</th>\n",
              "      <th>.</th>\n",
              "      <th>guided</th>\n",
              "      <th>...</th>\n",
              "      <th>webpage</th>\n",
              "      <th>not</th>\n",
              "      <th>client</th>\n",
              "      <th>Science</th>\n",
              "      <th>process</th>\n",
              "      <th>dataset</th>\n",
              "      <th>share</th>\n",
              "      <th>rewarded</th>\n",
              "      <th>category</th>\n",
              "      <th>act</th>\n",
              "      <th>below</th>\n",
              "      <th>wa</th>\n",
              "      <th>From</th>\n",
              "      <th>Catalog</th>\n",
              "      <th>business-ready</th>\n",
              "      <th>prescriptive</th>\n",
              "      <th>among</th>\n",
              "      <th>found</th>\n",
              "      <th>machine</th>\n",
              "      <th>far</th>\n",
              "      <th>underlying</th>\n",
              "      <th>breadth</th>\n",
              "      <th>,</th>\n",
              "      <th>former</th>\n",
              "      <th>collect</th>\n",
              "      <th>interacting</th>\n",
              "      <th>Today</th>\n",
              "      <th>doe</th>\n",
              "      <th>IT</th>\n",
              "      <th>At</th>\n",
              "      <th>so</th>\n",
              "      <th>get</th>\n",
              "      <th>opportunity</th>\n",
              "      <th>drag-and-drop</th>\n",
              "      <th>hidden</th>\n",
              "      <th>unique</th>\n",
              "      <th>resource</th>\n",
              "      <th>to</th>\n",
              "      <th>their</th>\n",
              "      <th>forced</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.009809</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.035372</td>\n",
              "      <td>0.017686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010069</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010069</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.017686</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010069</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001083</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.013344</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.015626</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015626</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.031251</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004448</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004448</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.007813</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.002479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.002479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003394</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "      <td>0.003394</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005961</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.004347</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001449</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.005950</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011900</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011900</td>\n",
              "      <td>0.005950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.010451</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.005950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.004210</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001053</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.012966</td>\n",
              "      <td>0.004322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004322</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.015183</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 392 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       data  understanding  architecture  ...   to     their    forced\n",
              "0  0.009809       0.000000      0.000000  ...  0.0  0.000000  0.000000\n",
              "1  0.000000       0.007813      0.000000  ...  0.0  0.000000  0.000000\n",
              "2  0.002479       0.000000      0.005961  ...  0.0  0.000000  0.005961\n",
              "3  0.004347       0.000000      0.000000  ...  0.0  0.000000  0.000000\n",
              "4  0.004210       0.000000      0.000000  ...  0.0  0.007592  0.000000\n",
              "\n",
              "[5 rows x 392 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4zK8tJXI7U5c"
      },
      "source": [
        "### c. Top TF-IDF words for the n-gram based input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt6f-Nyx7ZpS"
      },
      "source": [
        "# Converting documents as list\n",
        "listA = [documentA]\n",
        "listB = [documentB]\n",
        "listC = [documentC]\n",
        "listD = [documentD]\n",
        "listE = [documentE]"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UM9qrSSs7b8O"
      },
      "source": [
        "# Calculating N-gram\n",
        "resA = [(x, i.split()[j + 1]) for i in listA  \n",
        "       for j, x in enumerate(i.split()) if j < len(i.split()) - 1]\n",
        "resB = [(x, i.split()[j + 1]) for i in listB  \n",
        "       for j, x in enumerate(i.split()) if j < len(i.split()) - 1]\n",
        "resC = [(x, i.split()[j + 1]) for i in listC  \n",
        "       for j, x in enumerate(i.split()) if j < len(i.split()) - 1]\n",
        "resD = [(x, i.split()[j + 1]) for i in listD  \n",
        "       for j, x in enumerate(i.split()) if j < len(i.split()) - 1]\n",
        "resE = [(x, i.split()[j + 1]) for i in listE  \n",
        "       for j, x in enumerate(i.split()) if j < len(i.split()) - 1]"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Plp6IRZn7eU0",
        "outputId": "a8731636-e3c4-4619-9c59-8d221a2b22bc"
      },
      "source": [
        "# Removing duplicate words\n",
        "runiqueWords = set(resA).union(set(resB)).union(set(resC)).union(set(resD)).union(set(resE))\n",
        "len(runiqueWords)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "728"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gU83Gp6a7f0U"
      },
      "source": [
        "# Dictonary of all 5 documents\n",
        "rnumOfWordsA = dict.fromkeys(runiqueWords, 0)\n",
        "for word in resA:\n",
        "    rnumOfWordsA[word] += 1\n",
        "rnumOfWordsB = dict.fromkeys(runiqueWords, 0)\n",
        "for word in resB:\n",
        "    rnumOfWordsB[word] += 1\n",
        "rnumOfWordsC = dict.fromkeys(runiqueWords, 0)\n",
        "for word in resC:\n",
        "    rnumOfWordsC[word] += 1\n",
        "rnumOfWordsD = dict.fromkeys(runiqueWords, 0)\n",
        "for word in resD:\n",
        "    rnumOfWordsD[word] += 1\n",
        "rnumOfWordsE = dict.fromkeys(runiqueWords, 0)\n",
        "for word in resE:\n",
        "    rnumOfWordsE[word] += 1"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4hcHd2d7lCo"
      },
      "source": [
        "rtfA = computeTF(rnumOfWordsA, resA)\n",
        "rtfB = computeTF(rnumOfWordsB, resB)\n",
        "rtfC = computeTF(rnumOfWordsC, resC)\n",
        "rtfD = computeTF(rnumOfWordsD, resD)\n",
        "rtfE = computeTF(rnumOfWordsE, resE)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVTvDXy37ny7"
      },
      "source": [
        "ridfs = computeIDF([rnumOfWordsA, rnumOfWordsB, rnumOfWordsC, rnumOfWordsD, rnumOfWordsE])\n"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "5Oz0v_4a7o8h",
        "outputId": "19b67bd6-4dca-459e-dce4-9474f293103f"
      },
      "source": [
        "# Calculating TFIDF of n-grams\n",
        "rtfidfA = computeTFIDF(rtfA, ridfs)\n",
        "rtfidfB = computeTFIDF(rtfB, ridfs)\n",
        "rtfidfC = computeTFIDF(rtfC, ridfs)\n",
        "rtfidfD = computeTFIDF(rtfD, ridfs)\n",
        "rtfidfE = computeTFIDF(rtfE, ridfs)\n",
        "rdf = pd.DataFrame([rtfidfA, rtfidfB, rtfidfC, rtfidfD, rtfidfE])\n",
        "rdf"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>(will, introduce)</th>\n",
              "      <th>(algorithms, find)</th>\n",
              "      <th>(services., These)</th>\n",
              "      <th>(we, are)</th>\n",
              "      <th>(framework,, we)</th>\n",
              "      <th>(AI, engagements.)</th>\n",
              "      <th>(site, updates)</th>\n",
              "      <th>(supervised, ML,)</th>\n",
              "      <th>(to, provide)</th>\n",
              "      <th>(to, impart)</th>\n",
              "      <th>(the, environment.)</th>\n",
              "      <th>(then, share)</th>\n",
              "      <th>(a, must-have)</th>\n",
              "      <th>(it, also)</th>\n",
              "      <th>(acts, as)</th>\n",
              "      <th>(for, Data.)</th>\n",
              "      <th>(and, developed)</th>\n",
              "      <th>(the, cloud.)</th>\n",
              "      <th>(you, can)</th>\n",
              "      <th>(barriers, to)</th>\n",
              "      <th>(platform, value)</th>\n",
              "      <th>(enterprise, data)</th>\n",
              "      <th>(when, the)</th>\n",
              "      <th>(both, talent)</th>\n",
              "      <th>(in, that,)</th>\n",
              "      <th>(learning, models,)</th>\n",
              "      <th>(the, benefits)</th>\n",
              "      <th>(Catalog, as)</th>\n",
              "      <th>(on, the)</th>\n",
              "      <th>(an, agent)</th>\n",
              "      <th>(services, spanning)</th>\n",
              "      <th>(penalized, or)</th>\n",
              "      <th>(AI, life)</th>\n",
              "      <th>(key, to)</th>\n",
              "      <th>(services,, patterns,)</th>\n",
              "      <th>(the, beginning)</th>\n",
              "      <th>(Unsupervised, Machine)</th>\n",
              "      <th>(industries, across)</th>\n",
              "      <th>(for, just)</th>\n",
              "      <th>(its, integration)</th>\n",
              "      <th>...</th>\n",
              "      <th>(Data, platform)</th>\n",
              "      <th>(answer., Instead,)</th>\n",
              "      <th>(clients, confront)</th>\n",
              "      <th>(you, grow,)</th>\n",
              "      <th>(trying, to)</th>\n",
              "      <th>(just, the)</th>\n",
              "      <th>(it, can)</th>\n",
              "      <th>(required, to)</th>\n",
              "      <th>(as-a-Service, delivery:)</th>\n",
              "      <th>(developed, an)</th>\n",
              "      <th>(everything, related)</th>\n",
              "      <th>(from, previous)</th>\n",
              "      <th>(address, both.)</th>\n",
              "      <th>(unified, data)</th>\n",
              "      <th>(came, IBM)</th>\n",
              "      <th>(supervised, learning,)</th>\n",
              "      <th>(big, data.)</th>\n",
              "      <th>(underlying, IT)</th>\n",
              "      <th>(can, present.)</th>\n",
              "      <th>(for, you)</th>\n",
              "      <th>(services, available)</th>\n",
              "      <th>(includes, a)</th>\n",
              "      <th>(of, pre-integrated)</th>\n",
              "      <th>(aspirations, into)</th>\n",
              "      <th>(spanning, the)</th>\n",
              "      <th>(either, penalized)</th>\n",
              "      <th>(offer, your)</th>\n",
              "      <th>(interacting, with)</th>\n",
              "      <th>(with, the)</th>\n",
              "      <th>(the, cloud)</th>\n",
              "      <th>(tries, to)</th>\n",
              "      <th>(and, multicloud)</th>\n",
              "      <th>(Unsupervised, machine)</th>\n",
              "      <th>(you, collect,)</th>\n",
              "      <th>(data, and)</th>\n",
              "      <th>(wide, array)</th>\n",
              "      <th>(including, Watson)</th>\n",
              "      <th>(that, bridges)</th>\n",
              "      <th>(AI, platform)</th>\n",
              "      <th>(or, even)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020373</td>\n",
              "      <td>0.020373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.020373</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002854</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.003740</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008991</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002102</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003771</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000918</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006306</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.006623</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.007403</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001617</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.011663</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.003702</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.004699</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.016507</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.001144</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.002620</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.008254</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 728 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   (will, introduce)  (algorithms, find)  ...  (AI, platform)  (or, even)\n",
              "0           0.000000            0.000000  ...        0.000000    0.000000\n",
              "1           0.008991            0.008991  ...        0.000000    0.008991\n",
              "2           0.000000            0.000000  ...        0.006623    0.000000\n",
              "3           0.000000            0.000000  ...        0.000000    0.000000\n",
              "4           0.000000            0.000000  ...        0.000000    0.000000\n",
              "\n",
              "[5 rows x 728 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MJVlCUw77It"
      },
      "source": [
        "# Write a simple spark program to read a dataset and find the W2V similar words (words with higher cosine similarity) for the Top10 TF-IDF Words"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRfN7Gqw8RRg"
      },
      "source": [
        "### a. Try Without NLP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZmxhzVFOAU2",
        "outputId": "cf055829-b33b-41ce-9bbb-920a97ded699"
      },
      "source": [
        "pip install pyspark"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pyspark\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/67/5158f846202d7f012d1c9ca21c3549a58fd3c6707ae8ee823adcaca6473c/pyspark-3.0.2.tar.gz (204.8MB)\n",
            "\u001b[K     |████████████████████████████████| 204.8MB 55kB/s \n",
            "\u001b[?25hCollecting py4j==0.10.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/b6/6a4fb90cd235dc8e265a6a2067f2a2c99f0d91787f06aca4bcf7c23f3f80/py4j-0.10.9-py2.py3-none-any.whl (198kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 46.9MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: pyspark\n",
            "  Building wheel for pyspark (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyspark: filename=pyspark-3.0.2-py2.py3-none-any.whl size=205186687 sha256=13bb619b51e6eb5fd91f162ff333d135c69fd3fe00cba279c11c5583cc3b1911\n",
            "  Stored in directory: /root/.cache/pip/wheels/8b/09/da/c1f2859bcc86375dc972c5b6af4881b3603269bcc4c9be5d16\n",
            "Successfully built pyspark\n",
            "Installing collected packages: py4j, pyspark\n",
            "Successfully installed py4j-0.10.9 pyspark-3.0.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MMg3_h0t7sJE"
      },
      "source": [
        "from __future__ import print_function\n",
        "from pyspark import SparkContext\n",
        "from pyspark.mllib.feature import HashingTF, IDF"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1yPZ6Fvh8Ybk"
      },
      "source": [
        "# Importing text document\n",
        "sc = SparkContext.getOrCreate()\n",
        "documents = sc.textFile(\"/content/text3.txt\").map(lambda line: line.split(\" \"))"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaoJUh3F8atM"
      },
      "source": [
        "# Calculating TFIDF\n",
        "\n",
        "hashingTF = HashingTF(numFeatures=20)\n",
        "tf = hashingTF.transform(documents)\n",
        "\n",
        "tf.cache()\n",
        "idf = IDF().fit(tf)\n",
        "tfidf = idf.transform(tf)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KFgCGRPR83OX",
        "outputId": "e613416b-8cef-4da7-b2c7-7651d46a7223"
      },
      "source": [
        "print(\"TFIDF without NLP:\")\n",
        "for each in tfidf.collect():\n",
        "    print(each)\n",
        "sc.stop()"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TFIDF without NLP:\n",
            "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n",
            "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19],[0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0,0.0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BSApVrWH8_OB"
      },
      "source": [
        "### b. Try with Lemmatization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nxLxxPTt87yd",
        "outputId": "ea1a6443-90e3-476d-a3d0-53e062cd72fd"
      },
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from pyspark import SparkContext\n",
        "from pyspark.mllib.feature import HashingTF, IDF\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "sc = SparkContext.getOrCreate()\n",
        "documents = sc.textFile(\"/content/text3.txt\").map(lambda line: line.split(\" \"))\n",
        "\n",
        "# Lemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "word_list = list(map(' '.join, documents.collect()))\n",
        "word_list1 = ''\n",
        "for i in word_list:\n",
        "    word_list1 = word_list1 + ' ' + i\n",
        "word_list2 = nltk.word_tokenize(word_list1)\n",
        "lemmatized_document = ' '.join([lemmatizer.lemmatize(w) for w in word_list2])\n",
        "print(lemmatized_document)\n",
        "\n",
        "# Storing text document in new \"Data1.txt\"\n",
        "\n",
        "f = open(\"data1.txt\", \"w+\")\n",
        "f.write('' + lemmatized_document)\n",
        "f.close()\n",
        "\n",
        "document1 = sc.textFile(\"/content/text2.txt\").map(lambda line: line.split(\" \"))\n",
        "\n",
        "# Calculting TFIDF\n",
        "\n",
        "hashingTF = HashingTF(numFeatures=20)\n",
        "tf = hashingTF.transform(document1)\n",
        "tf.cache()\n",
        "idf = IDF().fit(tf)\n",
        "tfidf = idf.transform(tf)\n",
        "\n",
        "print(\"TFIDF with Lemmatization:\")\n",
        "for each in tfidf.collect():\n",
        "    print(each)\n",
        "sc.stop()"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "At IBM , we understand both the exponential benefit AI can offer your organization a well a the unique challenge implementation can present . In 2018 , we formalized the AI Ladder to provide a prescriptive approach to successful AI , and to impart lesson we ’ ve learned through over 30,000 AI engagement . From that framework and methodology came IBM Cloud Pak for Data , our unified data and AI platform . IBM Cloud Pak for Data provides the flexible foundation and information architecture required for advanced analytics and AI on the cloud of your choice . The platform is designed to modernize how you collect , organize and analyze data and infuse AI throughout your organization . A key to the value of the platform is it integration of leading service spanning the entire AI life cycle . Building on this framework , we are now helping address some of the other concern our client confront when trying to turn AI aspiration into real business result . For many , IT resource , both talent and infrastructure , can be costly barrier to entry when deploying AI capability . COVID-19 is now impacting industry across the board and continuing to redefine our “ new normal. ” In this environment , many business leader have found themselves forced to digitally transform far faster than originally planned , while also minimizing expense . We looked at this challenge and developed an innovative solution that bridge the integrated data and AI platform value with the benefit of an as-a-Service delivery : IBM Cloud Pak for Data a a Service .\n",
            "TFIDF with Lemmatization:\n",
            "(20,[0,1,2,3,4,5,6,7,8,9,10,13,17,18],[0.28768207245178085,1.9616585060234524,2.9424877590351786,2.4800357195534035,1.1631508098056809,1.9616585060234524,0.9808292530117262,1.1507282898071236,0.9808292530117262,0.9808292530117262,0.9808292530117262,1.3862943611198906,1.1631508098056809,0.8266785731844679])\n",
            "(20,[0],[0.28768207245178085])\n",
            "(20,[0,1,2,3,4,5,6,7,8,9,10,11,13,14,15,16,18,19],[0.5753641449035617,3.9233170120469048,0.9808292530117262,3.3067142927378717,2.3263016196113617,0.9808292530117262,1.9616585060234524,2.301456579614247,2.9424877590351786,0.9808292530117262,3.9233170120469048,1.6739764335716716,1.3862943611198906,5.021929300715015,2.3263016196113617,2.4800357195534035,1.6533571463689358,0.9808292530117262])\n",
            "(20,[0],[0.28768207245178085])\n",
            "(20,[7,16,19],[0.5753641449035618,0.8266785731844679,0.9808292530117262])\n",
            "(20,[0],[0.28768207245178085])\n",
            "(20,[1,2,3,4,5,6,7,8,9,10,15,16,17,18,19],[0.9808292530117262,2.9424877590351786,2.4800357195534035,2.3263016196113617,1.9616585060234524,1.9616585060234524,1.1507282898071236,2.9424877590351786,1.9616585060234524,1.9616585060234524,1.1631508098056809,0.8266785731844679,6.978904858834085,1.6533571463689358,1.9616585060234524])\n",
            "(20,[0],[0.28768207245178085])\n",
            "(20,[7,18],[0.5753641449035618,0.8266785731844679])\n",
            "(20,[0],[0.28768207245178085])\n",
            "(20,[0,1,2,3,5,6,7,8,9,10,13,15,16,17,18,19],[0.8630462173553426,1.9616585060234524,0.9808292530117262,3.3067142927378717,0.9808292530117262,2.9424877590351786,0.5753641449035618,1.9616585060234524,2.9424877590351786,1.9616585060234524,2.772588722239781,1.1631508098056809,1.6533571463689358,6.978904858834085,1.6533571463689358,3.9233170120469048])\n",
            "(20,[0],[0.28768207245178085])\n",
            "(20,[3,7,16],[0.8266785731844679,0.5753641449035618,0.8266785731844679])\n",
            "(20,[0],[0.28768207245178085])\n",
            "(20,[0,1,2,3,4,5,6,7,8,9,10,11,12,14,15,16,17,18,19],[0.5753641449035617,0.9808292530117262,1.9616585060234524,2.4800357195534035,5.8157540490284045,0.9808292530117262,0.9808292530117262,0.5753641449035618,2.9424877590351786,2.9424877590351786,1.9616585060234524,1.6739764335716716,4.1588830833596715,1.6739764335716716,1.1631508098056809,0.8266785731844679,3.4894524294170424,0.8266785731844679,2.9424877590351786])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KOnj5N0v9U_s"
      },
      "source": [
        "### c. Try with N-Grams"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjyLxWNj9PjG",
        "outputId": "b999ed88-267b-47dd-ee2c-f132bcdc07e9"
      },
      "source": [
        "import nltk\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pandas as pd\n",
        "\n",
        "txt1 = []\n",
        "# Importing text document\n",
        "with open('/content/text1.txt') as file:\n",
        "    txt1 = file.readlines()\n",
        "\n",
        "def remove_string_special_characters(s):\n",
        "    stripped = re.sub('[^a-zA-z\\s]', '', s)\n",
        "    stripped = re.sub('_', '', stripped)\n",
        "    stripped = re.sub('\\s+', ' ', stripped)\n",
        "    stripped = stripped.strip()\n",
        "    if stripped != '':\n",
        "        return stripped.lower()\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "your_list = ['skills', 'ability', 'job', 'description']\n",
        "for i, line in enumerate(txt1):\n",
        "    txt1[i] = ' '.join([x for\n",
        "                        x in nltk.word_tokenize(line) if\n",
        "                        (x not in stop_words) and (x not in your_list)])\n",
        "\n",
        "vectorizer = CountVectorizer(ngram_range=(2, 2))\n",
        "X1 = vectorizer.fit_transform(txt1)\n",
        "features = (vectorizer.get_feature_names())\n",
        "print(\"\\n\\nFeatures : \\n\", features)\n",
        "print(\"\\n\\nX1 : \\n\", X1.toarray())\n",
        "\n",
        "vectorizer = TfidfVectorizer(ngram_range=(3, 3))\n",
        "X2 = vectorizer.fit_transform(txt1)\n",
        "scores = (X2.toarray())\n",
        "print(\"\\n\\nScores : \\n\", scores)\n",
        "\n",
        "# Getting top ranking features \n",
        "sums = X2.sum(axis=0)\n",
        "data1 = []\n",
        "for col, term in enumerate(features):\n",
        "    data1.append((term, sums[0, col]))\n",
        "ranking = pd.DataFrame(data1, columns=['term', 'rank'])\n",
        "words = (ranking.sort_values('rank', ascending=False))\n",
        "print(\"\\n\\nWords head : \\n\", words.head(10))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "Features : \n",
            " ['acts online', 'also offers', 'analytics technology', 'array data', 'big data', 'blog posts', 'central exactly', 'code opportunities', 'community forum', 'contribute discussion', 'contributing writers', 'covers wide', 'data science', 'data the', 'data visualization', 'day contributing', 'discussion insights', 'discussion questions', 'everything related', 'exactly name', 'experts contribute', 'forum discussion', 'frequently nearly', 'hub everything', 'industry experts', 'insights key', 'key topics', 'name suggests', 'nearly two', 'offers community', 'online resource', 'opportunities industry', 'posts day', 'regarding analytics', 'related data', 'resource hub', 'science big', 'science central', 'science topics', 'site covers', 'site updates', 'suggests acts', 'technology tools', 'the site', 'tools data', 'topics regarding', 'topics the', 'two blog', 'updates frequently', 'visualization code', 'wide array', 'writers also']\n",
            "\n",
            "\n",
            "X1 : \n",
            " [[1 1 1 1 1 1 1 1 1 1 1 1 3 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            "  1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1]]\n",
            "\n",
            "\n",
            "Scores : \n",
            " [[0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276\n",
            "  0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276\n",
            "  0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276\n",
            "  0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276\n",
            "  0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276\n",
            "  0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276\n",
            "  0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276\n",
            "  0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276\n",
            "  0.13608276 0.13608276 0.13608276 0.13608276 0.13608276 0.13608276]]\n",
            "\n",
            "\n",
            "Words head : \n",
            "                       term      rank\n",
            "0              acts online  0.136083\n",
            "1              also offers  0.136083\n",
            "28              nearly two  0.136083\n",
            "29        offers community  0.136083\n",
            "30         online resource  0.136083\n",
            "31  opportunities industry  0.136083\n",
            "32               posts day  0.136083\n",
            "33     regarding analytics  0.136083\n",
            "34            related data  0.136083\n",
            "35            resource hub  0.136083\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SOaoj5nX9duQ"
      },
      "source": [
        ""
      ],
      "execution_count": 70,
      "outputs": []
    }
  ]
}